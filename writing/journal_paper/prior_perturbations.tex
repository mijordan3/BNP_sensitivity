We now consider two classes of prior perturbations: parametric and
non-parametric.  Recall from \eqref{sens_mixed_partial} that we
need to specify a map $\t \mapsto \log \pstick(\nuk \vert \t)$.

First, consider the parametric case where we take $\t = \alpha$ and
%
\begin{align*}
%
\pstick(\nuk \vert \alpha) ={}&
    \betadist{\nuk \vert 1, \alpha} \Rightarrow\\
\log \pstick(\nuk \vert \alpha) ={}&
    (\alpha - 1) \log(1 - \nuk) + \const. &
    \constdesc{\nuk}
%
\end{align*}
%
In this case,
%
\begin{align*}
%
\expect{\q(\nuk \vert \eta)}
       {\fracat{\log \pstick(\nuk \vert \alpha)}{\partial \alpha}{\alpha_0}
} ={}&
    \expect{\q(\nuk \vert \eta)}{\log(1 - \nuk)}.
%
\end{align*}
%
We can thus numerically compute the needed derivatives.

To consider more general prior perturbations, fix for the mometn a base stick
distribution, $\pb(\nuk)$ and an alternative stick distribution
$\pa(\nuk)$.  Take $\t = \epsilon$ and define
%
\begin{align*}
%
\pstick(\nuk \vert \epsilon) ={}&
\frac{\pb(\nuk)^{1 - \epsilon} \pa(\nuk)^\epsilon}
     {\int_0^1 \pb(\nuk')^{1 - \epsilon} \pa(\nuk')^\epsilon d\nuk'}.
%
\end{align*}
%
We thus have that $\epsilon$ parameterizes a multiplicative path from
$\pb(\nuk)$ to $\pa(\nuk)$, with $\pstick(\nuk \vert \epsilon = 0) = \pb(\nuk)$
and $\pstick(\nuk \vert \epsilon=1) = \pa(\nuk)$.  We will take
$\t_0$ to be $\epsilon = 0$, so that we are computing $\etaopt$ with the
prior $\pb(\nuk)$ and approximating the optimum if we had used $\pa(\nuk)$.
%
Given this definition,
%
\begin{align*}
%
\fracat{\partial \log \pstick(\nuk \vert \epsilon) }{\partial \epsilon}{0} ={}&
    \log \frac{\pa(\nuk)}{\pb(\nuk)} + \const.
    & \constdesc{\nuk}
%
\end{align*}
%
Again, for a fixed $\pa(\nuk)$ we can compute the needed derivatives.

There are many (an infinite number!) of $\pa(\nuk)$ to choose from, and so it
can be useful to think of $\etaopt(\epsilon)$ as functional of the stick
breaking prior, following \citet{gustafson:1996:local}.  Let us fix $\pb(\nuk)$,
define $\phi(\nuk) := \epsilon \log \left(\pa(\nuk) / \pb(\nuk)\right)$, and
re-write $\pstick(\nuk \vert \epsilon)$ in the following equivalent form:
%
\begin{align}\eqlabel{phi_perturbation}
%
\pstick(\nuk \vert \phi) ={}&
\frac{\exp\left(\log \pb(\nuk) + \phi(\nuk)\right)}
     {\int_0^1 \exp\left(\log \pb(\nuk') + \phi(\nuk')\right) d\nuk'}.
%
\end{align}
%
The advantage of \eqref{phi_perturbation} is that $\pstick(\nuk \vert \phi)$ is
well-defined for any Lebesgue-integrable function $\phi(\nuk):
(0,1)\mapsto\mathbb{R}$, and a valid distribution for any $\phi$ such that the
denominator is positive and finite.
Define the norm
%
\begin{align*}
%
\norminf{\phi} :={} \esssup_{\nuk} |\phi(\nuk)|.
%
\end{align*}
%
Under this norm, $\phi$ is a member of the Banach space $\linf$ equipped with
the Borel sets and Lebesgue measure (e.g.,
\citet[Section 2.1, Example 5]{luenberger:1997:optimization} and
\citet[Theorem 5.2.1]{dudley:2018:real}).

Note that
%
\begin{align*}
%
\exp(-\norminf{\phi}) \le{}
\abs{\int_0^1 \exp\left(\log \pb(\nuk) + \phi(\nuk)\right) d\nuk}
\le{}
\exp(\norminf{\phi}),
%
\end{align*}
%
so that $\pstick(\nuk \vert \phi)$ is a valid distribution whenever
$\norminf{\phi} < \infty$.  (As pointed out by \citet{gustafson:1996:local}, the
converse is not true---there exist valid distributions with infinte
$\norminf{\phi}$.)

Analogous to \eqref{kl_shorthand}, we can write $\etaopt(\phi) := \argmin_{\eta
\in \etadom} \KL{\eta, \phi}$ for the optimal variational parameters when
using the prior $\pstick(\nuk \vert \phi)$.  The optimum $\etaopt(\phi)$
is thus a functional of $\phi$.

Observe that
%
\begin{align*}
%
\log \pstick(\nuk \vert \phi) ={}&
    \log \pb(\nuk) + \phi(\nuk) + \const
    & \constdesc{\nuk} \Rightarrow\\
\KL{\eta, \phi} ={}&
    \KL{\eta, 0} + \sumkm \expect{\q(\nuk \vert \eta)}{\phi(\nuk)}.
%
\end{align*}
%
Let $\phiz(\cdot)$ denote the zero function.  Then, using \eqref{vb_eta_sens}
gives that the directional (Gateaux) derivative in the direction $\phi$
evaluated at $\phiz$ is given by
%
\begin{align*}
%
\fracat{d \etaopt(\phi)}{d \phi}{\phiz} ={}&
    - \hess{\zeta\zeta}^{-1}
    \evalat{
        \sumkm \frac{\partial}{\partial \eta}
            \expect{\q(\nuk \vert \eta)}{\phi(\nuk)}}
           {\etaopt(\phiz), \phiz}.
%
\end{align*}
%
Differentiating under the integral in $\expect{\q(\nuk \vert
\eta)}{\phi(\nuk)}$ gives
%
\begin{align*}
%
\evalat{
\frac{\partial}{\partial \eta}
    \expect{\q(\nuk \vert \eta)}{\phi(\nuk)}
}{\etaopt} ={}&
\expect{\q(\nuk \vert \etaoptnuk)}
       {\evalat{\frac{\partial}{\partial \etanuk}
                  \log\q(\nuk \vert \etanuk)}
                {\etaoptnuk}
        \phi(\nuk)} \\
={}&
\int_0^1
    \q(\nu \vert \etaoptnuk)
    \evalat{\frac{\partial}{\partial \etanuk}
               \log\q(\nu \vert \etanuk)}
             {\etaoptnuk}
    \phi(\nu) d\nu.
%
\end{align*}
%
Plugging in gives
%
\begin{align*}
%
\fracat{d \etaopt(\phi)}{d \phi}{\phiz} =&{}
    \int_0^1
    -\hess{\zeta\zeta}^{-1}
    \left(
        \sumkm
        \q(\nu \vert \etaoptnuk)
        \fracat{\partial \log\q(\nu \vert \etanuk)}
               {\partial \etanuk}
               {\etaoptnuk}
    \right) \phi(\nu) d\nu.
%
\end{align*}
%
Thus, the influence function for $\etaopt(\psi)$ at $\phiz$ is given by
%
\begin{align*}
%
\infl(\nu) :={}&
-\hess{\zeta\zeta}^{-1}
\left(
    \sumkm
    \q(\nu \vert \etaoptnuk)
    \fracat{\partial \log\q(\nu \vert \etanuk)}
           {\partial \etanuk}
           {\etaoptnuk}
\right) \\
\fracat{d \etaopt(\phi)}{d \phi}{\phiz} =&{}
    \int_0^1 \infl(\nu) \phi(\nu) d\nu.
%
\end{align*}
%
Analogously, for a differentiable function of interest $g(\eta)$,
the influence function is given via \eqref{vb_g_sens} to be
%
\begin{align*}
%
\inflg(\nu) :={}&
-\fracat{\partial g(\eta)}{\partial \eta^T}{\etaopt(\t_0)}
    \hess{\zeta\zeta}^{-1}
\left(
    \sumkm
    \q(\nu \vert \etaoptnuk)
    \fracat{\partial \log\q(\nu \vert \etanuk)}
           {\partial \etanuk}
           {\etaoptnuk}
\right) \\
\fracat{d g(\etaopt(\phi))}{d \phi}{\phiz} =&{}
    \int_0^1 \inflg(\nu) \phi(\nu) d\nu.
%
\end{align*}
%
The influence funciton is a convenient summary of the effect of functional prior
perturbations on a differnetiable summary statistic, as we will show below.

An additional benefit of the influence function is that it admits a closed-form
expression for the ``worst-case'' perturbation in an $\norminf{\cdot}$ ball
via Holder's inequality, since
%
\begin{align*}
%
\sup_{\phi: \norminf{\phi} \le \delta}
    \fracat{d g(\etaopt(\phi))}{d \phi}{\phiz} =&{}
\sup_{\phi: \norminf{\phi} \le \delta}
    \int_0^1 \inflg(\nu) \phi(\nu) d\nu \\
\le&{} \delta \int_0^1 \abs{\inflg(\nu) }d\nu,
%
\end{align*}
%
with equality when $\phi(\nu) = \delta \, \mathrm{sign}(\inflg(\nu))$.

In order for the supremum over a bounded set $\phi: \norminf{\phi} < \delta$
to be meaningful, a minimal requirement is that the function $\etaopt(\phi)$
be Fr{\'e}chet differentiable.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thm}
%
Assume that $\eta \mapsto \KL{\eta, \phiz}$ is twice continuously
differentiable in a neighborhood of $\etaopt(\phiz)$, and that
%
\begin{align*}
%
\fracat{\partial^2 \KL{\eta, \phiz}}
                {\partial \eta \partial \eta^T}
                {\eta}%
\end{align*}
%
is positive definite in a neighborhood of $\etaopt(\phiz)$.

Additionally, assume that, for each $\k$, and any bounded, Lebesgue-integrable
function $f(\cdot)$, the map $\eta \mapsto \expect{\q(\nuk \vert \eta)}{f(\nuk)}$
is continuously differentiable.

Then the map $\phi \mapsto \etaopt(\phi)$ is Fr{\'e}chet differentiable
as a map from $\linf$ to $\mathbb{R}^\etadim$.
%
\begin{proof}
%
The map $\eta, \phi \mapsto \KL{\eta, \phi}$ is a map from the Banach space
$\mathbb{R}^\etadim \times \linf$ into the Banach space $\mathbb{R}$. Let us
take the L2 norm $\norm{\cdot}_2$ on the Euclidian spaces.  Let $\ball$ denote a
ball in $\mathbb{R}^\etadim \times \linf$ centered at $(\etaopt(\phiz), \phiz)$.

For the duration of the proof, define
%
\begin{align*}
%
\KLgrad{\eta, \psi} :={}&
    \fracat{\partial \KL{\eta, \psi}}{\partial \eta}{\eta, \psi}\\
\KLhess{\eta, \psi} :={}&
    \fracat{\partial^2 \KL{\eta, \psi}}
           {\partial \eta \partial \eta^T}{\eta, \psi}.
%
\end{align*}
%
The key to the proof will be showing that $\KL{\eta, \psi}$  and $\KLgrad{\eta,
\psi}$ are continuously Fr{\'e}chet differentiable, and that $\KLhess{\eta,
\psi}$ is positive definite in a ball centered at $\etaopt(\phiz), \phiz$.  The
result will then follow from the implicit function theorem \citet[Theorem
4.B(d)]{zeidler:2013:functional}.

First, observe that
%
\begin{align*}
%
\KL{\eta, \phi} ={}&
    \KL{\eta, \phiz} + \sumkm \expect{\q(\nuk \vert \eta)}{\phi(\nuk)}.
%
\end{align*}
%
By assumption $\eta \mapsto \KL{\eta, \phiz}$ and $\eta \mapsto \KLgrad{\eta,
\phiz}$ are continuously differentiable, so we need to show that, for all $\k$,
$\eta, \phi \mapsto \expect{\q(\nuk \vert \eta)}{\phi(\nuk)}$ is continuously
differentiable at $\etaopt(\phiz), \phiz$.  Since $\norminf{\phi}$ is finite,
$\phi(\nuk)$ is bounded, so $\eta \mapsto \expect{\q(\nuk \vert
\eta)}{\phi(\nuk)}$ is continuously differentiable by assumption, and we
need only show that the map $\psi \mapsto \expect{\q(\nuk \vert
\eta)}{\phi(\nuk)}$ is continuously differentiable.

For two functions $\phi_1$ and $\phi_2$,
%
\begin{align*}
%
\abs{\expect{\q(\nuk \vert \eta)}{\phi_1(\nuk)} -
     \expect{\q(\nuk \vert \eta)}{\phi_2(\nuk)}}
\le{}&
\expect{\q(\nuk \vert \eta)}{\abs{\phi_1(\nuk) - \phi_2(\nuk)}}\\
\le{}&
\norminf{\phi_1(\nuk) - \phi_2(\nuk)},
%
\end{align*}
%
from which continunity follows.


\noindent\rule{\textwidth}{1pt}

OLD:

Other references: We will use the
formulation given in \citep[Theorem 3.4.10]{krantz:2012:implicit}, for which
we must show that... actually that doesn't give differentiability.
The result follows then from \citet[Proposition 4.8(c)]{zeidler:2013:functional}.
See also \citet[Corollary 1.4]{averbukh:1967:theory} and \citep[Appendix
A]{reeds:1976:thesis}).
%
\end{proof}
%
\end{thm}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
