
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{defn}
%
For a probability measure $\lambda$ on $(0,1)$ and $1 \le p \le \infty$, let
$\lp{\lambda,p}$ define the space of $\lambda$-integrable functions from
$(0,1)\mapsto\mathbb{R}$ with
%
\begin{align*}
%
\left(a \phi_1 + \phi_2 \right)(\theta) :={}&
    a \phi_1(\theta) + \phi_2(\theta) \\
\norm{\phi}_{\lambda,p} :={}&
\begin{cases}
    \left(\int \abs{\phi(\theta)}^p \lambda(d\theta)\right)^{1/p}
    & \textrm{when }1\le p < \infty\\
    \esssup_{\theta} \abs{\phi(\theta)}
    & \textrm{when }p = \infty.
\end{cases}
%
\end{align*}
%
When $\lambda$ is proportional to the  Lebesgue measure, we may simply write
$\norm{\cdot}_{p} = \norm{\cdot}_{\lambda,p}$.
%
\end{defn}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

By \citep[Theorem 5.2.1]{dudley:2018:real}, $\lp{\lambda,p}$ is a Banach
space (i.e., a complete, normed vector space).




In \secref{prior_perturbations} we considered a multiplicative perturbations
of the form \eqref{phi_perturbation} with the $\norminf{\cdot}$ norm.  In
this section we consider other norms, illustrating that other choices
have problems with KL divergence.

First, we recall what we hope to get from our linear approximation.  We wish to
approximation $\etaopt(\phi)$ using the linear approximation $\etalin(\phi)$
evaluated at $\phiz$, hoping that the error $\norm{\etaopt(\phi) -
\etalin(\phi)}_2$ is small whenever the $\norm{\phi}$ is small (for some choice
of $\norm{\cdot}$).  A bare minimum for such a local approximation to work is
for $\phi \mapsto \etaopt(\phi)$ to be continuous, so that, for any
$\phi$,
%
\begin{align*}
%
\lim_{t \rightarrow 0} \norm{\etaopt(t \phi) - \etaopt}_2 = 0.
%
\end{align*}
%
By this reasoning, however, $\etaopt$ itself is a ``good'' approximation to
$\etaopt(\phi)$ when $\norm{\phi}$ is small---when $\phi$ is small, by
continuity we can simply say that nothing has changed and be reasonably correct.
From our linear approximation, we expect another order of accuracy, namely that
%
\begin{align*}
%
\lim_{t \rightarrow 0} \frac{\norm{\etaopt(t \phi) - \etalin(t\phi)}_2}{t} = 0.
%
\end{align*}

The preceding display is enough if we have a fixed $\phi$ in mind.  However, if
we want to search over a larger set of candidate $\phi$, we want the derivative
to provide a {\em uniformly good approximation} to $\etaopt(\phi)$ amonst some
set of $\phi$, say, all bounded $\phi: \norm{\phi} \le 1$.  One way of
formalizing the notion of ``uniformaly good approximation'' follows.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}\deflabel{diffable_classes}
    (\citep[Definition 4.5]{zeidler:2013:functional})
%
Let $B_1$ and $B_2$ denote Banach spaces, and let $\ball_1 \subseteq B_1$ define
an open neighborhood of $\phi_0 \in B_1$.  Fix a function $f: \ball_1
\mapsto B_2$.

The function $f$ is {\em directionally differentiable} (also known as a Gateaux
differentiable) if there exists a bounded linear functional $f^{\mathrm{lin}}:
B_1 \mapsto B_2$ such that the following condition holds for any
$\phi$ with $\norm{\phi - \phi_0} < \infty$:
%
\begin{align*}
%
%\textrm{For any }\phi\textrm{ with }\norm{\phi - \phi_0} < \infty\textrm{, }
\lim_{t \rightarrow 0}
    \frac{f(\phi) - f(\phi_0) -
          f^{\mathrm{lin}}(t (\phi - \phi_0) )
         }{t} \rightarrow 0.
%
\end{align*}
%

Similarly, the function $f$ is {\em boundedly differentiable} (also known as
Fr{\'echet} differentiable) at $\phi_0$ if we can take the limit uniformly in
$\phi$:
%
\begin{align*}
%
\lim_{t \rightarrow 0}
    \sup_{\phi: \norm{\phi - \phi_0} = 1}
    \frac{f(\phi) - f(\phi_0) -
          f^{\mathrm{lin}}(t (\phi - \phi_0))
         }{t} \rightarrow 0.
%
\end{align*}
%
\end{defn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Note that we used the same notation $f^{\mathrm{lin}}$ for both derivatives in
\defref{diffable_classes}.  In fact, if a function is compactly differentiable
then the two derivatives must coincide \citep[Proposition
4.8]{zeidler:2013:functional}, which justifies our presumptuous notation.

% The difference between bounded and directional differentiability is whether the
% linear approximation holds uniformly in $\phi$.

It is possible for functions to be directionally but not boundedly
differentiable even in $\mathbb{R}^2$, as the following example demonstrates.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{r2_pathological}
%
Consider $(x_1, x_2) \in \mathbb{R}^2$ and the polar coordinates $r :=
\sqrt{x_1^2 + x_2^2}$ and $\theta := \arctan(x_2 / x_1)$.  Let $\{\pi k: k \in
\mathbb{Z} \}$ denote integer multiples of $\pi$.  Define
%
% \begin{align*}
% %
% f(r, \theta) := \begin{cases}
% \frac{\left(\frac{r}{| \sin \theta |}\right)^2}
%      {1 + \left(\frac{r}{| \sin \theta |}\right)^2}
%     & \textrm{when } \theta \notin \{\pi k: k \in \mathbb{Z}\}
%     \textrm{ and } r > 0 \\
% 0. & \textrm{when } \theta \in \{\pi k: k \in \mathbb{Z}
%     \} \textrm{ or }r = 0
% %
% \end{cases}
\begin{align*}
%
f(r, \theta) := \begin{cases}
    \left(\frac{r}{| \sin \theta |}\right)^2
        & \textrm{when } \theta \notin \{\pi k: k \in \mathbb{Z}\}
        \textrm{ and } r > 0 \\
    0. & \textrm{when } \theta \in \{\pi k: k \in \mathbb{Z}
        \} \textrm{ or }r = 0
%
\end{cases}
%
\end{align*}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h!]

\includegraphics[width=0.980\linewidth,height=0.490\linewidth]{static_images/pathological_r2_example.png}
\caption{A plot of $f(x_1, x_2)$ from \exref{r2_pathological}.}
\figlabel{r2_pathological}
\centering
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\Figref{r2_pathological} contains a plot of $f(r, \theta)$, both over
$\mathbb{R}^2$ and along paths for particular choices of $\theta$.

Then $f$ has a directional derivative in every direction, but is not Fr{\'e}chet
differentiable.  By ordinary calculus, for any $\theta$, $\fracat{\partial f(r,
\theta)}{\partial r}{r=0} = 0$, so the directional derivatives all exist and are
identically $0$.  However, for any $r$, there exists a $\theta(r)$ such that $r /
|\sin(\theta(r))| = 1$.  For such a choice of $\theta(r)$, the error in the
linear approximation is $f(r, \theta(r)) - 0 = 1/2$, which does not go to zero
as $r \rightarrow 0$.

\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Note that the second derivative in a particular direction is given by
$\fracat{\partial^2 f(r, \theta)}{\partial r^2}{r=0} = \frac{1}{2 |\sin
\theta|}$, which can be made arbitrarily large by taking $\theta$ close to $0$
or to $\pi$.  We could modify $f(r, \theta)$ to be Fr{\'e}chet differentiable
by smoothly ``capping'' $1 / |\sin \theta|$ at some arbitrarily large value.
However, the ability to meaningfully extrapolate $f(r, \theta)$ in the direction
of a very large but finite second derivative will still be extremely limited. In
this sense, Fr{\'e}chet differentiability is a weak necessary but not sufficient
requirement if we are interested in extrapolating using linear approximations.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{r2_pathological_v2}
%
In the context of \exref{r2_pathological}, fix some $0 < M < \infty$,
and define
%
\begin{align*}
%
\tilde{f}(r, \theta) := \begin{cases}
    f(r, \theta) & \textrm{when }\frac{1}{\abs{\sin(\theta)}} \le M \\
    0. & \textrm{when }\frac{1}{\abs{\sin(\theta)}} > M.
%
\end{cases}
%
\end{align*}
%
Then $\tilde{f}$ is continuous and Fr{\'e}chet differentiable at $r=0$. In this
case, for any $r$, $\sup_{\theta} r / |\sin(\theta(r))| = r / M$, so  both
$\lim_{r \rightarrow 0} \tilde{f}(r, \theta) \le \lim_{r \rightarrow 0} r^2 /
M^2 = 0$ and $\lim_{r \rightarrow 0} \tilde{f}(r, \theta) / r \le \lim_{r
\rightarrow 0}  r / M^2 = 0$.  (Note that $\tilde{f}$ is continuous only
at $r=0$, not on a ball centered at $0$.)

Despite being Fr{\'e}chet differentiable, the linear approximation may not
extrapolate well to any finite $r$.  In the direction $\theta = \sin^{-1}(1 /
M)$, the error of the linear extrapolation to any $r_0$ is still $\tilde{f}(r,
\theta) - 0 = M r_0^2$. Since Fr{\'e}chet differentiability requires only $M <
\infty$, the extraplation error can be arbitrarily large, even for Fr{\'e}chet
differentiable functions.

\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\Exref{r2_pathological} is neither Fr{\'e}chet differentiable nor continuous,
whereas \exref{r2_pathological} is both Fr{\'e}chet differentiable and
continuous.  In general, however, Fr{\'e}chet differentiability is stronger than
continuity, in the sense that Fr{\'e}chet differentiability implies continuity,
but continuity does not imply Fr{\'e}chet differentiability \citep[Proposition
4.8 (d)]{zeidler:2013:functional}.  See also \citet[Example
1.9]{averbukh:1967:theory} for a simple example of a function on $\mathbb{R}^2$
that is continuous and directionally differentiable but not Fr{\'e}chet
differentiable.

The sort of pathology exhibited by \exref{r2_pathological, r2_pathological_v2}
requires some care to construct in $\mathbb{R}^2$, but requires some care to
avoid in infinite-dimensional spaces.  We now give an illustrative example in
the $\lp{p}$ spaces; since the result will be important for VB prior
sensitivity, we will state is as a lemma rather than merely an example.

We can define the family of nonlinear perturbations similar to
\citep{gustafson:1996:local}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}\deflabel{prior_nl_pert}
%
Let $\pbase(\theta)$ be a density with respect to a probability measure
$\lambda$, and fix $1 \le p \le \infty$.  For any $\phi \in \lp{\lambda,p}$,
define \footnote{We have dropped a factor of $p$ from the perturbation when $p <
\infty$ relative to the definition in \citep{gustafson:1996:local}.}
%
\begin{align*}
%
\rho(\theta \vert \phi) :={}& \begin{cases}
%
\pbase(\theta)^{1/p} + \phi(\theta)
    & \textrm{when }p < \infty \\
\pbase(\theta)\exp(\phi(\theta))
    & \textrm{when }p = \infty
%
\end{cases}\\
%
\tilde{\p}(\theta \vert \phi) :={}&
    \mathrm{sign}(\rho(\theta \vert \phi)) \abs{\rho(\theta \vert \phi)}^p\\
\p(\nu \vert \phi) :={}&
    \frac{\tilde{\p}(\theta \vert \phi)}{\int \tilde{\p}(\theta' \vert \phi) d\theta'}.
%
\end{align*}
%
\end{defn}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Defref{prior_nl_pert} provides one class of answers to what it means to perturb
a prior, and how to measure the size of the perturbation.  \citep[Result
2]{gustafson:1996:local} states that using $\norm{\cdot}_{\lambda, p}$ with its
corresponding perturbation gives a notion of ``size'' of a perturbation that is
a norm, invariant to changes in the base measure, and invariant under one-to-one
re-parameterizations.

Unlike \citep{gustafson:1996:local}, we allow the perturbations $\phi$ to be
negative.  There are two reasons for doing so.  First, if $\phi$ must be
pointwise positive, then $\p(\theta \vert \phi)$ is not defined in an open ball
containing $\phiz$, and standard results from functional analysis cannot be
directly applied to establish properties like Fr{\'e}chet differentiability.
There may be priors that cannot be achieved by considering only positive
perturbations.  But perhaps most importantly, when $\phi$ must be positive, the
norm $\norm{\cdot}_{\lambda, p}$ treats ablating and adding prior mass very
asymmetrically when $p < \infty$, arguably violating an intutive notions of the
``size'' of perturbation.

Suppose $p < \infty$ and we wish to choose a $\phi$ to change $\pbase$ into
$\palt$, for which \defref{prior_nl_pert} gives that we must choose
%
\begin{align}\eqlabel{phi_for_palt}
%
\phi(\theta) = \alpha \palt(\theta)^{1/p} - \pbase(\theta)^{1/p}
    \mathtxt{where}\alpha > 0.
%
\end{align}
%
The fact that we are free to choose $\alpha$ follows from the fact that we
normalize after perturbing.  As long as $\palt(\nu) > 0$ whenever $\pbase(\nu) >
0$ (a condition which is certainly not always satisfied), one can choose
%
\begin{align*}
%
\alpha = \sup_{\nu} \left(\frac{\pbase(\nu)}{\palt(\nu)}\right)^{1/p}
%
\end{align*}
%
to guarantee that $\phi(\nu)$ is non-negative.  However, by doing so, one might
have to create a ``large'' perturbation, according to the $\norm{\cdot}_p$,
as the following \exref{positive_pert_large} demonstrates.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{ex}
% %
% Let $\pbase(\nu) = \frac{4}{3}\ind{\frac{1}{4} \le \nu \le 1}$ and $\palt(\nu) =
% \frac{4}{3}\ind{0 \le \nu \le \frac{3}{4}}$.  Then, for any $\alpha > 0$, any $1
% \le p < \infty$, and for $\phi$ as given in \eqref{phi_for_palt}, $\phi(7/8) <
% 0$.  So there is no value of $\alpha$ that can transform $\pbase$ into $\palt$
% using only a positive perturbation.
% %
% \end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{positive_pert_large}
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h!]

\includegraphics[width=0.980\linewidth,height=0.980\linewidth]{static_images/positive_phi_example.png}
%
\caption{A plot of the perturbations from \exref{positive_pert_large}
with $p=2$ and $\epsilon=0.05$.  Positive $\phi$ can only add mass, so to remove
a small amount of mass requires adding mass everywhere else and re-normalizing,
resulting in a large perturbation according to $\norm{\cdot}_p$.}
%
\figlabel{positive_pert_large}
\centering
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Let $\pbase(\nu) = \ind{0 \le \nu \le 1}$.  For some $\delta > 0$ and $0 <
\epsilon \ll 1$, let
%
\begin{align*}
%
\palt(\nu) :={}&
    \left(\frac{1-\delta \epsilon}{1 - \epsilon} \right)
        \ind{\epsilon \le \nu \le 1} +
    \delta \ind{0 \le \nu \le \epsilon}.
%
\end{align*}
%
% where the final approximation is due to the smallness of $\epsilon$.
Then \eqref{phi_for_palt} gives, for some $\alpha$,
%
\begin{align*}
%
\phi ={}&
    \left( \alpha\left(\frac{1-\delta \epsilon}{1-\epsilon} \right)^{1/p}
        - 1
    \right)
        \ind{\epsilon \le \nu \le 1} +
    \left(\alpha \delta^{1/p} - 1 \right) \ind{0 \le \nu \le \epsilon}.
%
%
\end{align*}
%
And
%
\begin{align*}
%
\norm{\phi}_p ={}&
    \left( \alpha\left(\frac{1-\delta \epsilon}{1-\epsilon} \right)^{1/p} - 1
    \right) (1- \epsilon) +
    \left(\alpha \delta^{1/p} - 1 \right) \epsilon.
%
\end{align*}
%
For $\phi$ to be positive, we require
%
\begin{align*}
%
\alpha^p \ge \frac{1 - \epsilon}{1 - \delta \epsilon}
    \mathtxt{and}
\alpha^p \ge \frac{1}{\delta}.
%
\end{align*}

First, let us consider adding a small amount of prior mass, taking $\delta = 2 -
\epsilon$; let the corresponding perturbation be $\phi^+$.  For $\delta > 1$,
then we achieve $\phi \ge 0$ by taking $\alpha^p = \frac{1 - \epsilon}{1 -
\delta \epsilon}$.  Using the fact that $\epsilon \ll 1$ and keeping only
leading-order terms,
%
\begin{align*}
%
\frac{1-\epsilon}{1 - \delta \epsilon} \approx{}&
    (1- \epsilon)(1 + \delta \epsilon)
\\\approx{}& 1 + (\delta - 1) \epsilon
\\\approx{}& 1 + \epsilon,
%
\end{align*}
%
so
%
\begin{align*}
%
\norm{\phi^+}_p  ={}&
    \left(\alpha \delta^{1/p} - 1 \right) \epsilon
\\\approx{}&
    \left(
        \left( \left(1 + \epsilon\right) \left(2 - \epsilon \right)\right)^{1/p}
        - 1 \right) \epsilon
\\\approx{}&
%
\left( 2^{1/p} - 1 \right) \epsilon.
%
\end{align*}
%

Next, consider removing the same amount of mass with the symmetric change
$\delta = \epsilon$, letting $\phi^-$ be the corresponding perturbation. Then we
can ensure that $\phi(\nu) \ge 0$ with $\alpha^p \ge \epsilon^{-1}$, and
$\epsilon \ll 1$ gives
%
\begin{align*}
%
\frac{1-\delta\epsilon}{1 - \epsilon} \approx{}& 1- \epsilon,
%
\end{align*}
%
and
%
\begin{align*}
%
\norm{\phi^-}_p  ={}&
    \left( \alpha\left(\frac{1-\delta \epsilon}{1-\epsilon} \right)^{1/p} - 1
    \right) (1- \epsilon)
\\\approx{}&
\left(\left(\frac{1- \epsilon}{\epsilon}  \right)^{1/p} - 1\right)(1 - \epsilon)
%
\\\approx{}&
    \left( \frac{1}{\epsilon}\right)^{1/p}.
%
\end{align*}

Since $\epsilon$ is small, $\norm{\phi^-}_p \approx \left(
\frac{1}{\epsilon}\right)^{1/p} \gg \norm{\phi^+}_p \approx \left( 2^{1/p} - 1
\right) \epsilon$, despite the two perturbations respectively removing and
adding the same amount of arbitrarily small probability mass.

\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Of course, if we relax the constraint that $\phi(\nu) \ge 0$, then we cannot
guarantee that $\pstick(\nu \vert \phi) \ge 0$ in an open ball around $\phiz$.
However, pointwise negative priors are no substantive problem, as long as
normalizing integral is neither zero nor infinity.  To that end, we state the
following generalization of \citep[Result 2]{gustafson:1996:local}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lem}
%
TODO: fix the notation here.

Fix a $1 \le p < \infty$ and $\pbase(\nu)$ as in \defref{prior_nl_pert}.
If $\norm{\phi}_p < 1$ then
%
\begin{align*}
%
\int_0^1 \pstick'(\nu \vert \phi) d\nu < \infty
\mathtxt{and}
\int_0^1 \pstick'(\nu \vert \phi) d\nu > 0.
%
\end{align*}
%
\begin{proof}
%
By Jensen's inequality applied pointwise to the convex function $x \mapsto
x^p$,
%
\begin{align*}
%
\abs{\pbase(\nu)^{1/p} + \phi(\nu) }^{p} \le{}&
    \left(\pbase(\nu)^{1/p} + \abs{\phi(\nu)} \right)^{p}
\\={}&
    2^p \left(\frac{1}{2}\pbase(\nu)^{1/p} +
              \frac{1}{2} \abs{\phi(\nu)} \right)^{p}
\\\le{}&
    2^{p-1} \left(\pbase(\nu) + \abs{\phi(\nu)}^p \right).
%
\end{align*}
%
Consequently,
%
\begin{align*}
%
\int \abs{\pbase(\nu)^{1/p} + \phi(\nu) }^{p} d\nu \le{}&
    2^{p-1} \int \left(\pbase(\nu) + \abs{\phi(\nu)}^p \right) d\nu
\\={}&
    2^{p-1} \left(1 + \norm{\phi}_p^p\right).
%
\end{align*}
%
So, as in \citep[Result 2]{gustafson:1996:local}, $\norm{\phi}_p < \infty$
implies that the prior can be normalized.

Next, by convexity,\footnote{Apply the definition of convexity to the points
$0$, $x$, and $x + y$, and again to the points $0$, $y$, and $x+y$, then add the
results.} for any $x \ge y \ge 0$,
%
\begin{align*}
%
(x + y)^p \ge{} x^p + y^p \mathand
(x - y)^p \le{} x^p - y^p.
%
\end{align*}
%
Also note that, since $\pbase(\nu) \ge 0$,
%
\begin{align*}
%
\pbase(\nu)^{1/p} + \phi(\nu) \le 0
\quad\Rightarrow\quad
\phi(\nu) \le 0 \mathand
\abs{\phi(\nu)} - \pbase(\nu)^{1/p} \ge 0.
%
\end{align*}
%
We can thus write
%
\begin{align*}
%
\MoveEqLeft
\int \mathrm{sign}(\pbase(\nu)^{1/p} + \phi(\nu))
    \abs{\pbase(\nu)^{1/p} + \abs{\phi(\nu)}}^{p} d\nu
={}\\&
    \int \left(\pbase(\nu)^{1/p} + \phi(\nu)\right)^{p}
        \ind{\pbase(\nu)^{1/p} + \phi(\nu) \ge 0}
        d\nu - \\&
    \int \left(\abs{\phi(\nu)} - \pbase(\nu)^{1/p}\right)^{p}
        \ind{\pbase(\nu)^{1/p} + \phi(\nu) < 0}
        d\nu
\\\ge{}&
    \int \left(\pbase(\nu) - \abs{\phi(\nu)}^{p}\right)
        \ind{\pbase(\nu)^{1/p} + \phi(\nu) \ge 0}
        d\nu - \\&
    \int \left(\abs{\phi(\nu)}^p - \pbase(\nu)\right)
        \ind{\pbase(\nu)^{1/p} + \phi(\nu) < 0}
        d\nu
\\={}&
    \int \pbase(\nu) d\nu - \int \abs{\phi(\nu)}^p d\nu
\\={}&
    1 - \norm{\phi}_p^p.
%
\end{align*}
%
\end{proof}
%
\end{lem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

It will be notationaly convenient in our discussion to treat the map $x \mapsto
\log(x)$ as simply discontinuous at $x = 0$, rather than undefined (or
complex-valued). Define the ``trimmed log'' function as

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}
%
\begin{align*}
%
\logtrim(x) :=
\begin{cases}
    \log x  &\textrm{when }x > 0 \\
    0       &\textrm{when }x \le 0.
\end{cases}
%
\end{align*}
%
% In order for the directional derivative to exist in the direction of
% functions unbounded below, the value must be \log(1) = zero when undefined
%
% Otherwise, the when $x \le 0$ is simply a placeholder; for our purposes, it would
% ideally be some abstract number that is distant from all real numbers but zero
% distance to itself.  (Neither $0$ nor $\infty$ quite fit the bill.) Mostly we
% will require that $\logtrim(x)$ is discontinuous in a neighborhood of $0$.
%
\end{defn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Observe, that, for $1 \le p < \infty$, we take the log perturbation given by
\defref{prior_nl_pert} is
%
\begin{align*}
%
\logtrim \p(\theta \vert \phi) ={}&
    \log \pbase(\theta) +
        \logtrim\left(1 + \frac{\phi(\theta)}{\pbase(\theta)^{1/p}} \right).
%
\end{align*}
%


We can now state our main results.


\begin{thm}
%
Fix $1 \le p < \infty$ and define a prior perturbation as in
\defref{prior_nl_pert}.
Assume that the variational approximations $\q(\nu \vert \etanuk)$ to the
stick-breaking posteriors satisfy \assuref{dist_fun_nice} with $\eta_0 =
\etaopt$, with $\psi(\zeta, \t) = 1$, and with $\psi(\zeta, \t) = \log\left(1 + \frac{\phi(\nu)}{\pbase(\nu)^{1/p}} \right)$, for all $\k$.

%
\end{thm}
