
The Dirichlet process has become a mainstay in unsupervised learning tasks
like clustering and topic modeling. Its stick-breaking representation in particular lends itself
to fast approximate posterior inference with variational Bayes. However, choices for the
stick-breaking representation are often made from convenience. For instance, particular
values of the concentration parameter are favored by different applications, and the beta
distribution of the sticks lends itself to conditional conjugacy and closed-form inferential updates.
In many cases, though, different values of the concentration parameter and the underlying stick-breaking
distribution could equally align with prior beliefs. If the major conclusions of our analysis changed under these different reasonable choices, we might worry that our conclusions were driven by arbitrary implementation choices rather than meaningful data trends.
In the present work we demonstrate how to assess the sensitivity of conclusions
to the choice of concentration parameter and stick-breaking distribution. While we focus on perturbations to stick-breaking priors in Bayesian nonparametrics, along the way we develop new theory to support sensitivity analysis more generally for variational Bayes.