We now state conditions under which $\t \mapsto \etaopt(\t)$, as defined by
\defref{prior_t}, is continuously differentiable.  Our key theoretical tool will
be the implicit function theorem (e.g., \citet{krantz:2012:implicit}), applied
to the first-order conditions for the VB optimization problem.

Our results can be expressed in terms of unnormalized densities, which can
simplify some computation.  To that end, let $\qtil$ and $\ptil$ refer to
potentially unnormalized (but normalizable) versions of the respectively
corresponding $\q$ and $\p$ given in \defref{prior_t}, so that
%
\begin{align*}
%
\q(\theta \vert \eta) :={}
    \frac{\qtil(\theta \vert \eta)}
    {\int \qtil(\theta' \vert \eta) \mu(d\theta')} \mathand
\p(\theta \vert \t) :={}
    \frac{\ptil(\theta \vert \t)}
    {\int \ptil(\theta' \vert \t) \mu(d\theta')}.
%
\end{align*}

First, in \assuref{kl_opt_ok}, we will require some mild regularity conditions
for the ``base problem,'' $\KL{\eta}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{kl_opt_ok}
%
Let the following conditions on the variational approximation hold.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
%
    \item \itemlabel{kl_diffable} The map $\eta \mapsto \KL{\eta}$ is twice
    continuously differentiable at $\etaopt$.

    \item\itemlabel{kl_hess} The Hessian matrix $\fracat{\partial^2 \KL{\eta}}
    {\partial \eta \partial \eta^T} {\etaopt}$ is non-singular.

    \item \itemlabel{kl_opt_interior} There exists an open ball $\ball_\eta
    \subset \mathbb{R}^\etadim$ such that $\etaopt \in \ball_\eta \subset
    \etadom$.
%
\end{enumerate}
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As we discuss in \secref{diffable_concentration}, \assuref{kl_opt_ok} states
conditions that are typically satisfied when $\KL{\eta}$ can be optimized
numerically using unconstrained optimization.

Next, we will require some differentiability conditions for the perturbation and
the variational approximation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{assu}\assulabel{exchange_order}
%
Assume that the map $\eta \mapsto \qtil(\theta \vert \eta)$ is twice
continuously differentiable, and that the map $\t \mapsto \ptil(\theta \vert
\t)$ is continuously differentiable.

Further, assume that we can exchange the order of integration and
differentiation in the expressions $\int \qtil(\theta \vert \eta) \log
\ptil(\theta \vert \t) \mu(d\theta)$ and $\int \qtil(\theta \vert \eta)
\mu(d\theta)$ at $\eta = \etaopt$ and $\t = 0$ for the derivatives $\partial /
\partial \eta$, $\partial^2 / \partial \eta^2$, and $\partial^2 / \partial \eta
\partial \t$.
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In certain cases, one can verify \assuref{exchange_order} directly, such as when
$\expect{\q(\theta \vert \eta)}{\log \ptil(\theta \vert \t)}$ has a closed form.
For more general situations, the following straightforward extention of the
dominated convergence theorem \citep[Theorem 16.8]{billingsley:1986:probability}
is useful.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{assu}\assulabel{exchange_order_f}
%
Let $f(\theta, \eta, \t)$ be a function taking values in $\mathbb{R}$. Assume
that the partial derivatives $\partial / \partial \eta$, $\partial^2 / \partial
\eta^2$, and $\partial^2 / \partial \eta \partial \t$ of $f$ exist, are
continuous functions of $\eta$ and $\t$, and are $\mu$-measureable functions of
$\theta$ on some open set $\ball_\eta \times \ball_\t$.

Let $M(\theta) > 0$ be a measurable function with $\int M(\theta) \mu(d\theta) <
\infty$.  Assume that, for all $\eta, \t \in \ball_\eta \times \ball_\t$,
$M(\theta)$ is $\mu$-almost everywhere greater than each of the following
functions: $\abs{f(\theta, \eta, \t)}$, $\norm{\partial f(\theta, \eta, \t) /
\partial \eta}_2$, $\norm{\partial^2 f(\theta, \eta, \t) / \partial \eta
\partial \eta^T}_2$, and $\norm{\partial^2 f(\theta, \eta, \t) / \partial \eta
\partial \t}_2$.
%
\end{assu}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{assu}\assulabel{exchange_order_dom}
(Sufficient conditions for \assuref{exchange_order}.)
%
Assume that \assuref{exchange_order_f} applies with the function $f(\theta,
\eta, \t) = \qtil(\theta \vert \eta) \log \ptil(\theta \vert \t)$ as well as
with $f(\theta, \eta, \t) = \qtil(\theta \vert \eta)$ (no $\t$ dependence).
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

By the dominated convergence theorem, \assuref{exchange_order_dom} implies
\assuref{exchange_order} (see \lemref{exchange_order} in \appref{proofs} for a
proof). The advantage of \assuref{exchange_order_dom} over
\assuref{exchange_order} is that the conditions of \assuref{exchange_order_dom}
can typically be verified even when the expectation $\expect{\q(\theta \vert
\eta)}{\log \ptil(\theta \vert \t)}$ does not have a closed form.  In
\secref{diffable_concentration}, we will dicuss how different choices of
variational approximations for the stick lengths lend themselves to either
\assuref{exchange_order} of \assuref{exchange_order_dom}.  Furthermore,
\assuref{exchange_order_f} will be essential to analyzing nonparametric
perturbations in \secref{diffable_nonparametric}.

We are now in a position to define the quantities that occur in the derivative
and state our main result.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}\deflabel{deriv_quantities}
%
Under the conditions of \defref{prior_t}, when \assuref{kl_opt_ok,
exchange_order} hold, define
%
\begin{align*}
%
\hessopt :={}& \fracat{\partial^2 \KL{\eta}}
                      {\partial \eta \partial \eta^T}
                      {\etaopt} \mathand \\
%
\lqgradbar{\theta \vert \etaopt} :={}&
    \lqgrad{\theta \vert \etaopt} -
    \expect{\q(\theta \vert \etaopt)}{\lqgrad{\theta \vert \etaopt}}.
%
\end{align*}

% Note that if $\qtil(\theta \vert \eta)$ is already normalized ($\qtil = \q$),
% then $\expect{\q(\theta \vert \eta)}{\lqgrad{\theta \vert \eta}} = 0$ for all
% $\eta$ and $\lqgradbar{\theta \vert \etaopt} = \lqgrad{\theta \vert \etaopt}$.

Further, define

\begin{align*}
%
\crosshessian :={}&
    \fracat{\partial
            \expect{\q(\theta \vert \etaopt)}
                   {\fracat{\partial \log \ptil(\theta \vert \t)}
                           {\partial \t}{\t=0} }
            }
        {\partial \eta}{\etaopt}
={}
    \expect{\q(\theta \vert \etaopt)}{
          \lqgradbar{\theta \vert \etaopt}
          \fracat{\partial \log \ptil(\theta \vert \t)}
                 {\partial \t}{\t=0}},
%
\end{align*}
%
where the final equality follows from differentiating under the integral using
\assuref{exchange_order} (see \lemref{logq_continuous} in \appref{proofs} for
more details).
%
\end{defn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thm}\thmlabel{etat_deriv}
%
Under the conditions of \defref{prior_t, deriv_quantities}, let
\assuref{kl_opt_ok, exchange_order} hold.   Then the map $\t \mapsto
\etaopt(\t)$ is continuously differentiable at $\t=0$ with derivative
%
\begin{align}\eqlabel{vb_eta_sens}
%
\fracat{d \etaopt(\t)}{d \t}{0} ={}&
    - \hessopt^{-1} \crosshessian.
%
\end{align}
%
(For a proof, see \appref{proofs} \proofref{etat_deriv}.)
%
\end{thm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The derivative given in \eqref{vb_eta_sens} involves two terms: $\hessopt^{-1}$
and  $\crosshessian$.  Typically, $\crosshessian$, which is a derivative of a
variational expectation, is simple to evaluate.  Forming and inverting or
factorizing $\hessopt$ can present a challenge, since $\hessopt$ has dimensions
$\etadim \times \etadim$, which can be very large.  Nevertheless, in many
cases---including our BNP problem---we can take advantage of model sparsity to
effeciently compute \eqref{vb_eta_sens}.  We take up these computational
considerations in detail in \secref{computing_sensitivity} below.
