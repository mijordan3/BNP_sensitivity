In the previous section, we showed that we can differentiate the VB optimum with
respect to $\alpha$ in the $\gem$ prior, which we can use to form a Taylor
series to how $\etaopt(\alpha)$ varies within the $\gem$ family.  However, there
is typically no {\em a priori} reason to believe that the stick breaking prior
lies within the parametric Beta family.  We now show how, by parameterizing a
path between two arbitrary densities, we can apply \thmref{etat_deriv} to
nonparametric perturbations.

Again let us return to the abstract setting of \defref{prior_t}. Let us fix an
initial prior density, $\pbase(\theta)$, at which we have computed a VB
approximation, and suppose we wish to ask what the variational optimum would
have been had we used some alternative prior density, $\palt(\theta)$. For
example, in the BNP setting, one might take $\pbase(\theta)$ to be
$\betadist{\nuk \vert \alpha_0}$, and $\palt(\theta)$ to be some generic
function of $\theta$ outside the Beta family. Let us write $\etaopt(\pbase)$ and
$\etaopt(\palt)$ for these two approximations, respectively, so we are
interested in quantifying the change $\g(\etaopt(\palt)) - \g(\etaopt(\pbase))$.
If this change is large, we say that our quantity of interest is not robust to
replacing $\pbase$ with $\palt$.

To approximately assess robustness using the local sensitivity approach of
\secref{local_sensitivity}, we must somehow define a continuous path from
$\pbase(\theta)$ to $\palt(\theta)$ parameterized, say, by $\t \in [0, 1]$. One
way to do so is to define a multiplicative path
%
\begin{align}
%
\log \ptil(\theta \vert \t) ={}&
    (1 - \t)\log \pbase(\theta) + \t \log \palt(\theta).
        \eqlabel{mult_pert_simple}
%
\end{align}
%
Under \eqref{mult_pert_simple}, when $\t=0$, $\p(\theta \vert \t) =
\pbase(\theta)$, when $\t=1$, $\p(\theta \vert \t, \pbase, \palt) =
\palt(\theta)$, and $\t \in (0,1)$ smoothly parameterizes a path between the
two.  If we can verify that \thmref{etat_deriv} applies to the perturbation
given in \eqref{mult_pert_simple}, then, just as in the parametric case, we can
form the Taylor series approximation,
%
\begin{align*}
%
\etaopt(\palt) \approx
    \etaopt(\pbase) + \fracat{d \etaopt(\t)}{d\t}{\t=0} (1 - 0).
%
\end{align*}

Our first task is then to state conditions under which \thmref{etat_deriv}
applies to \eqref{mult_pert_simple}.  In \eqref{mult_pert_simple} we have
assumed that $\palt$ is a density, but it will be more convenient to observe
that, when $\palt \ll \pbase$, we can re-write
%
\begin{align*}
%
\log \ptil(\theta \vert \t) ={}&
    \log \pbase(\theta) +
        \t \log \frac{\palttil(\theta)}{\pbasetil(\theta)} +
        \const. & \constdesc{\theta}
%
\end{align*}
%
Defining the generic function $\phi(\theta) := \log
\frac{\palttil(\theta)}{\pbasetil(\theta)}$ motivates consideration of
perturbations of the form $\log \ptil(\theta \vert \t) = \pbase(\theta) + \t
\phi(\theta)$, where $\phi(\theta)$ is some generic measurable function. We can
then ask what $\phi$ give rise to valid densities as well as differentiable maps
$\t \mapsto \etaopt(\t)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}\deflabel{prior_nl_pert}
%
Let $\mu$ denote a measure and fix $\pbase(\theta)$, a density with respect to
$\mu$.  Assume that $\pbase(\theta) > 0$ on $\thetadom$. For any measurable
$\phi: \thetadom \mapsto \mathbb{R}$ for which the expressions are well-defined,
let
%
\begin{align*}
\ptil(\theta \vert \phi) :={}& \pbase(\theta)\exp(\phi(\theta)).
%
\end{align*}
%
As usual, when $0 < \int \ptil(\theta \vert \phi) \mu(d\theta) < \infty$, we let
$\p(\theta \vert \phi)$ be the normalized version of $\ptil(\theta \vert \phi)$.
Further, define the norm $\norminf{\phi} := \esssup_{\theta \sim \mu}
\abs{\phi(\theta)}$, and let $\ball_\phi(\delta) := \left\{ \phi: \norminf{\phi} <
\delta \right\}$.
\todo{Tamara rightly points out that there is a need for $\mu$ and
$\pbase$ to be mutually absolutely continuous, where $\pbase$ is fixed.
This is awkward as $\pbase$ is now defined as a density, but it is actually
the distribution induced by $\pbase$ that is the fundamental object.}
%
\end{defn}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The class of perturbations defined in \defref{prior_nl_pert} are one of the
family of ``nonlinear'' functional perturbations given by
\citet{gustafson:1996:local}, though we deviate from
\citet{gustafson:1996:local} by allowing $\phi$ to take on negative values. The
following result, which motivates the use of the $\norminf{\cdot}$ norm to
measure the ``size'' of a perturbation $\phi$, is only a minor modification of
the corresponding result from \citet{gustafson:1996:local} to allow negative
perturbations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lem}\lemlabel{pert_invariance}
%
(\citet{gustafson:1996:local})
%
Fix the quantities given in \defref{prior_nl_pert}.  For a fixed probability
measure $\palt \ll \mu$, let $\phi(\theta \vert \palt) := \log \palt(\theta) /
\pbase(\theta)$.  Then $\palt \mapsto \norminf{\phi(\cdot \vert \palt)}$ is a
norm, does not depend on $\mu$, and is invariant to invertible transformations
of $\theta$.
\todo{Make sure this works with the corrected \defref{prior_nl_pert} }

Furthermore, for any $\phi$ with $\norminf{\phi} < \infty$, the quantity
$\ptil(\theta \vert \phi)$ gives rise to a valid prior, in the sense that
$\ptil(\theta \vert \phi) \ge 0$ $\mu$-almost everywhere, and
$0 < \int \ptil(\theta \vert \phi) \mu(d\theta) < \infty$.
%
\seeproof{pert_invariance}
%
\end{lem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The set of priors $\left\{\p(\theta \vert \phi) : \phi \in
\ball_\phi(\delta)\right\}$ live in a multiplicative band around the original
prior, $\pbase$, as shown in \figref{func_ball}. Although
\lemref{pert_invariance} proves that every $\phi$ with $\norminf{\phi}$ is a
valid prior, the converse is not true, and the Beta prior perturbation of
\exref{alpha_perturbation} is a counterexample.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{beta_inf_norm}
%
Take $\mu$ to be the Lebesgue measure on $[0,1]$, let $\pbase(\theta) =
\betadist{\theta \vert 1, \alpha_0}$ and $\palt(\theta) = \betadist{\theta \vert
1, \alpha_1}$ for $\alpha_0 \ne \alpha_1$.  Taking
$\phi(\theta) = (\alpha_1 - \alpha_0) \log(1 - \theta)$ parameterizes
a path from $\pbase$ to $\palt$ as in \eqref{mult_pert_simple}, and
%
\begin{align*}
%
\norminf{\phi} =
    \abs{\alpha_1 - \alpha_0} \sup_{\theta \in [0,1]} \abs{\log(1 - \theta)} =
    \infty.
%
\end{align*}
%
Therefore, in general, there exist valid priors that cannot be expressed by
\defref{prior_nl_pert} with $\phi$ with $\norminf{\phi} < \infty$.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now show that, when $\norminf{\phi} < \infty$, we can apply
\thmref{etat_deriv}.  We still require the following assumption on the VB
density, which is strictly weaker than \assuref{exchange_order_dom}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{exchange_order_q}
%
Assume that \assuref{exchange_order_f} applies with the function $f(\theta,
\eta, \t) = \q(\theta \vert \eta)$ (no $\t$ dependence).
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{cor}\corylabel{etafun_deriv_form}
%
Fix the quantities given in \defref{prior_nl_pert}, and let \assuref{kl_opt_ok,
exchange_order_q} hold. Let $g(\eta): \etadom \mapsto \mathbb{R}$ denote a
continuously differentiable real-valued function of interest.  Define the
``influence function'' $\infl: \thetadom \mapsto \mathbb{R}$:
%
\begin{align}\eqlabel{infl_defn}
%
\infl(\theta) :={}&
    - \fracat{d g(\eta)}{ d \eta^T}{\etaopt} \hessopt^{-1}
        \lqgradbar{\theta \vert \etaopt}
        \q(\theta \vert \etaopt).
%
\end{align}
%
Then, if $\norminf{\phi} < \infty$, the map $\t \mapsto g(\etaopt(\t \phi))$ is
continuously differentiable at $\t=0$ with derivative
%
\begin{align}\eqlabel{vb_eta_infl_sens}
%
\fracat{d g(\etaopt(\t \phi))}{d \t}{0} ={}&
    \int \infl(\theta) \phi(\theta) \mu(d\theta).
%
\end{align}
%
\begin{proof}
%
It suffices to show that \assuref{exchange_order_q} implies
\assuref{exchange_order} for the perturbation given in \defref{prior_nl_pert}
when $\norminf{\phi} < \infty$.  Observe that $\log \ptil(\theta \vert \t) = \t
\phi(\theta)$, so, for any $f(\theta, \eta, \t)$ that satisfies the conditions
of \assuref{exchange_order_f},
%
%\begin{align*}
%
$\phi(\theta) f(\theta, \eta, \t) \le \norminf{\phi} M(\theta)$.
%
%\end{align*}
%
Therefore \assuref{exchange_order_f} is satisfied by $\phi(\theta) f(\theta,
\eta, \t)$ as well.  It follows that \assuref{exchange_order_q} $\Rightarrow$
\assuref{exchange_order_dom} $\Rightarrow$ \assuref{exchange_order}.
%
The form of the influence function is then given by gathering terms in
\eqref{vb_eta_sens}.
%
\end{proof}
%
\end{cor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The influence function can be a useful summary of the effect of making generic
changes to the prior density, as we will show in the experiments of
\secref{results}.  For visualization, it can be useful to reduce the dimension
of the domain of the influence function, as we discuss in the following example.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{infl_univariate}
%
In the BNP example, we are perturbing each of the sticks, so we take $\theta \in
[0,1]^{\kmax - 1}$.  Formally, $\phi: [0,1]^{\kmax - 1} \mapsto \mathbb{R}$ can
express different perturbations for the density of each of the $\kmax - 1$
sticks.  However, when we describe ``changing the stick breaking density,'' we
mean changing each stick's prior density in the same way.

To represent perturbing all the sticks simultaneously, take some univariate
perturbation $\phi_{u}: [0,1] \mapsto \mathbb{R}$, and set $\phi(\nu_1, \ldots,
\nu_{\kmax - 1}) = \sum_{\k=1}^{\kmax - 1} \phi_{u}(\nuk)$. By linearity of the
derivative \coryref{etafun_deriv_form},
%
\begin{align*}
%
\fracat{d g(\etaopt(\t \phi))}{d \t}{0} ={}&
    \int \infl(\theta) \left(
        \sum_{\k=1}^{\kmax - 1} \phi_{u}(\nuk) \right)
    d\nu_1 \ldots d \nu_{\kmax - 1}.
%
\end{align*}
%
By definition, $\expect{\q(\theta \vert \etaopt)}{\lqgradbar{\theta \vert
\etaopt}} = 0$, so $\int \infl(\theta) \mu(d\theta) = 0$.  By the mean field
assumption, $\infl(\nu_1, \ldots, \nu_{\kmax - 1}) = \prod_{\k=1}^{\kmax - 1}
\infl_\k(\nuk)$, where $\infl_\k(\nuk)$ is derived from \eqref{infl_defn} but
using $\theta = \nuk$.  Letting $\nu_0 \in [0,1]$ denote the variable of
integration and plugging in the preceding observations gives
%
\begin{align*}
%
\int \infl(\theta) \phi(\theta) \mu(d\theta) =
    \int_0^1 \left(\sum_{\k=1}^{\kmax - 1} \infl_k(\nu_0) \right)
        \phi_{u}(\nu_0) d \nu_0.
%
\end{align*}
%
Thus we can say that the influence function for perturbing all the stick
breaking densities simultaneously is given by the sum of the
individual sticks' influence functions, which maps $[0,1] \mapsto \mathbb{R}$.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
