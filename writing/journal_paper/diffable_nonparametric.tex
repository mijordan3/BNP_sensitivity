In the previous section, we showed that we can form a Taylor series
approximation to the dependence of a variational optimum on the parameter
$\alpha$ in the GEM prior.  However, there is typically no {\em a priori} reason
to believe that the stick breaking prior lies within the parametric Beta family.
By parameterizing a path between two arbitrary densities, we can apply
\thmref{etat_deriv} to nonparametric perturbations. In this section, following
\citet{gustafson:1996:local}, we define paths through the space of prior
densities using multiplicative perturbations, and identify a norm on the
perturbation which guarantees both that the perturbed prior is a proper prior
and that \thmref{etat_deriv} can be applied.

% \todo{Not all this notation is still needed in the new draft}
% First, we must introduce some additional measure theory notation. Below, we will
% take $\lambda$ to denote the Lebesgue measure on the Borel sets of $\thetadom
% \subseteq \mathbb{R}^{\thetadim}$.  As in \defref{prior_t}, we will be
% interested in densities with respect to $\lambda$, expressed as Radon-Nikodym
% derivatives, though it will be convenient to use the same notation for a density
% and for the measure induced by the density.  Specifically, for a
% $\mu$-measurable set $S$, and a Radon-Nikodym derivative $f$ defined with
% respect to $\mu$, we will write $f(S) = \int_{\theta \in S} f(\theta)
% \mu(d\theta)$.  We similarly extend the notation for measure domination: for two
% densities $f$ and $g$, we will write $f \ll g$ to mean that $g(S) = 0
% \Rightarrow f(S) = 0$ for all $\mu$-measurable sets $S$.
% Finally, let
% $\esssup_{\theta\sim\mu}$ denote the essential supremum over $\theta$ with
% respect to the measure $\mu$.

Again let us return to the abstract setting of \defref{prior_t}. Let us fix a
base prior density, $\pbase(\theta)$, at which we have computed a VB
approximation, and suppose we wish to ask what the variational optimum would
have been had we used some alternative prior density, $\palt(\theta)$. For
example, in the BNP setting, one might take $\pbase(\theta)$ to be
$\betadist{\nuk \vert \alpha_0}$, and $\palt(\theta)$ to be some generic
function of $\theta$ outside the Beta family. Let us write $\etaopt(\pbase)$ and
$\etaopt(\palt)$ for these two approximations, respectively, so we are
interested in quantifying the change $\g(\etaopt(\palt)) - \g(\etaopt(\pbase))$.

To approximately answer this question using the local sensitivity approach of
\secref{local_sensitivity}, we must somehow define a continuous path from
$\pbase(\theta)$ to $\palt(\theta)$ parameterized, say, by $\t \in [0, 1]$. One
way to do so is to define a multiplicative path
%
\begin{align}
%
\log \ptil(\theta \vert \t) ={}&
    (1 - \t)\log \pbase(\theta) + \t \log \palt(\theta).
        \eqlabel{mult_pert_simple}
%
\end{align}
%
Under \eqref{mult_pert_simple}, when $\t=0$, $\p(\theta \vert \t) =
\pbase(\theta)$, when $\t=1$, $\p(\theta \vert \t, \pbase, \palt) =
\palt(\theta)$, and $\t \in (0,1)$ smoothly parameterizes a path between the
two.  If we can verify that \thmref{etat_deriv} applies to the perturbation
given in \eqref{mult_pert_simple}, then, just as in the parametric case, we can
form the Taylor series approximation,
%
\begin{align*}
%
\etaopt(\palt) \approx
    \etaopt(\pbase) + \fracat{d \etaopt(\t)}{d\t}{\t=0} (1 - 0).
%
\end{align*}

Our first task is then to state conditions under which \thmref{etat_deriv}
applies to \eqref{mult_pert_simple}.  Note that, in \eqref{mult_pert_simple} we
have assumed that $\palt$ is a density, but it will be more convenient to
observe that, when $\palt \ll \pbase$, we can re-write
%
\begin{align*}
%
\log \ptil(\theta \vert \t) ={}&
    \log \pbase(\theta) +
        \t \log \frac{\palttil(\theta)}{\pbasetil(\theta)} +
        \const. & \constdesc{\theta}
%
\end{align*}
%
Defining the generic function $\phi(\theta) := \log
\frac{\palttil(\theta)}{\pbasetil(\theta)}$ motivates consideration of
perturbations of the form $\log \ptil(\theta \vert \t) = \pbase(\theta) + \t
\phi(\theta)$, where $\phi(\theta)$ is some generic measurable function. We can
then ask what $\phi$ give rise to valid densities as well as differentiable maps
$\t \mapsto \etaopt(\t)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}\deflabel{prior_nl_pert}
%
Let $\mu$ denote a measure and fix $\pbase(\theta)$, a density with respect to
$\mu$.  Assume that $\pbase(\theta) > 0$ on $\thetadom$. For any measurable
$\phi: \thetadom \mapsto \mathbb{R}$ for which the expressions are well-defined,
let
%
\begin{align*}
% \p(\theta \vert \phi) :={}&
% \frac{\pbase(\theta)\exp(\phi(\theta))}
%      {\int \pbase(\theta')\exp(\phi(\theta')) \mu(d \theta')}.
\ptil(\theta \vert \phi) :={}& \pbase(\theta)\exp(\phi(\theta)).
%
\end{align*}
%
As usual, when $0 < \int \ptil(\theta \vert \phi) \mu(d\theta) < \infty$, we let
$\p(\theta \vert \phi)$ be the normalized version of $\ptil(\theta \vert \phi)$.
Further, define the norm $\norminf{\phi} := \esssup_{\theta \sim \mu}
\abs{\phi(\theta)}$, and let $\ball_\phi(\delta) := \left\{ \phi: \norminf{\phi} <
\delta \right\}$.
%
\end{defn}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The class of perturbations defined in \defref{prior_nl_pert} are one of the
family of ``nonlinear'' functional perturbations given by
\citet{gustafson:1996:local}, though we deviate from
\citet{gustafson:1996:local} by allowing $\phi$ to take on negative values. The
following result is only a minor modification of the corresponding result from
\citet{gustafson:1996:local} to allow negative perturbations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lem}\lemlabel{pert_invariance}
%
(\citet{gustafson:1996:local})
%
Fix the quantities given in \defref{prior_nl_pert}.  For a fixed probability
measure $\p \ll \mu$, let $\phi(\theta \vert \p) := \log \p(\theta) /
\pbase(\theta)$.  Then $\p \mapsto \norminf{\phi(\cdot \vert \p)}$ is a
norm, does not depend on $\mu$, and is invariant to invertible transformations
of $\theta$.

Furthermore, for any $\phi$ with $\norminf{\phi} < \infty$, the quantity
$\ptil(\theta \vert \phi)$ gives rise to a valid prior, in the sense that
$\ptil(\theta \vert \phi) \ge 0$ $\mu$-almost everywhere, and
$0 < \int \ptil(\theta \vert \phi) \mu(d\theta) < \infty$.
%
\seeproof{pert_invariance}
%
\end{lem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The set of priors $\left\{\p(\theta \vert \phi) : \phi \in
\ball_\phi(\delta)\right\}$ live in a multiplicative band around the original
prior, $\pbase$, as shown in \figref{func_ball}. Although
\lemref{pert_invariance} proves that every $\phi$ with $\norminf{\phi}$ is a
valid prior, the converse is not true, and the Beta prior perturbation of
\exref{alpha_perturbation} is a counterexample.

\FunctionBallFig{}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{beta_inf_norm}
%
Take $\mu$ to be the Lebesgue measure on $[0,1]$, let $\pbase(\theta) =
\betadist{\theta \vert 1, \alpha_0}$ and $\palt(\theta) = \betadist{\theta \vert
1, \alpha_1}$ for $\alpha_0 \ne \alpha_1$.  Taking
$\phi(\theta) = (\alpha_1 - \alpha_0) \log(1 - \theta)$ parameterizes
a path from $\pbase$ to $\palt$ as in \eqref{mult_pert_simple}, and
%
\begin{align*}
%
\norminf{\phi} =
    \abs{\alpha_1 - \alpha_0} \sup_{\theta \in [0,1]} \abs{\log(1 - \theta)} =
    \infty.
%
\end{align*}
%
Therefore, in general, there exist valid priors that cannot be expressed by
\defref{prior_nl_pert} with $\phi$ with $\norminf{\phi} < \infty$.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now show that, when $\norminf{\phi} < \infty$, we can apply
\thmref{etat_deriv}.  We still require the following assumption on the VB
distribution, which is strictly weaker than \assuref{exchange_order_dom}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{exchange_order_q}
%
Assume that \lemref{exchange_order} applies with the function $f(\theta, \eta,
\t) = \q(\theta \vert \eta)$ (no $\t$ dependence).
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{cor}\corlabel{etafun_deriv_form}
%
Let \assuref{kl_opt_ok, exchange_order_q} hold and fix the quantities given in
\defref{prior_nl_pert}. Let $g(\eta): \etadom \mapsto \mathbb{R}$ denote a
continuously differentiable real-valued function of interest.  Define the
``influence function'' $\infl: \thetadom \mapsto \mathbb{R}$:
%
\begin{align}\eqlabel{infl_defn}
%
\infl(\theta) :={}&
    - \fracat{d g(\eta)}{ d \eta^T}{\etaopt} \hessopt^{-1}
        \lqgradbar{\theta \vert \etaopt}
        \q(\theta \vert \etaopt).
%
\end{align}
%
Then, if $\norminf{\phi} < \infty$, the map $\t \mapsto g(\etaopt(\t \phi))$ is
continuously differentiable at $\t=0$ with derivative
%
\begin{align}\eqlabel{vb_eta_infl_sens}
%
\fracat{d g(\etaopt(\t \phi))}{d \t}{0} ={}&
    \int \infl(\theta) \phi(\theta) \mu(d\theta).
%
\end{align}
%
\begin{proof}
%
It suffices to show that \assuref{exchange_order_q} implies
\assuref{exchange_order} for the perturbation given in \defref{prior_nl_pert}
when $\norminf{\phi} < \infty$.  Observe that $\log \ptil(\theta \vert \t) = \t
\phi(\theta)$, so, for any $f(\theta, \eta, \t)$ that satisfies the conditions
of \lemref{exchange_order},
%
%\begin{align*}
%
$\phi(\theta) f(\theta, \eta, \t) \le \norminf{\phi} M(\theta)$.
%
%\end{align*}
%
Therefore \lemref{exchange_order} applies to $\phi(\theta) f(\theta, \eta, \t)$
as well.  It follows that \assuref{exchange_order_q} $\Rightarrow$
\assuref{exchange_order_dom} $\Rightarrow$ \assuref{exchange_order}.
%
The form of the influence function is then given by gathering terms in
\eqref{vb_eta_sens}.
%
\end{proof}
%
\end{cor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exref{infl_univariate}
%
In the BNP example, we are perturbing each of the sticks, so we take $\theta \in
[0,1]^{\kmax - 1}$.  Formally, $\phi: [0,1]^{\kmax - 1} \mapsto \mathbb{R}$ can
express different perturbations for the density of each of the $\kmax - 1$
sticks.  However, when we describe ``changing the stick breaking density,'' we
mean changing each stick's prior density in the same way.

To represent perturbing all the sticks simultaneously, take some univariate
perturbation $\phi_{u}: [0,1] \mapsto \mathbb{R}$, and set $\phi(\nu_1, \ldots,
\nu_{\kmax - 1}) = \sum_{\k=1}^{\kmax - 1} \phi_{u}(\nuk)$. By linearity of the
derivative \corref{etafun_deriv_form},
%
\begin{align*}
%
\fracat{d g(\etaopt(\t \phi))}{d \t}{0} ={}&
    \int \infl(\theta) \left(
        \sum_{\k=1}^{\kmax - 1} \phi_{u}(\nuk) \right)
    d\nu_1 \ldots d \nu_{\kmax - 1}.
%
\end{align*}
%
By definition, $\expect{\q(\theta \vert \etaopt)}{\lqgradbar{\theta \vert
\etaopt}} = 0$, so $\int \infl(\theta) \mu(d\theta) = 0$.  By the mean field
assumption, $\infl(\nu_1, \ldots, \nu_{\kmax - 1}) = \prod_{\k=1}^{\kmax - 1}
\infl_\k(\nuk)$, where $\infl_\k(\nuk)$ is derived from \eqref{infl_defn} but
using $\theta = \nuk$.  Letting $\nu_0 \in [0,1]$ denote the variable of
integration and plugging in the preceding observations gives
%
\begin{align*}
%
\int \infl(\theta) \phi(\theta) \mu(d\theta) =
    \int_0^1 \left(\sum_{\k=1}^{\kmax - 1} \infl_k(\nu_0) \right)
        \phi_{u}(\nu_0) d \nu_0.
%
\end{align*}
%
Thus we can say that the influence function for perturbing all the stick
breaking distributions simultaneously is given by the sum of the
individual sticks' influence functions, which maps $[0,1] \mapsto \mathbb{R}$.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
