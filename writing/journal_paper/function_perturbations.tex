In \corref{gem_approximation_ok} of \secref{local_sensitivity}, we showed that
we can form a Taylor series approximation to the dependence of a variational
optimum on the parameter $\alpha$ in a Beta prior. However, there is typically
no {\em a priori} reason to believe that the stick breaking prior lies within
the parametric Beta family.  In this section, we follow
\citet{gustafson:1996:local} and define a class of ways to perturb to the
functional form of the prior, corresponding to the $\lp{p}$ classes of
integrable functions (which we will define and discuss below).

For any particular perturbation, \thmref{etat_deriv} can be applied directly by
verifying \assuref{q_stick_regular}.  However, we will argue that it is
typically more useful to examine the form of the derivative to find influential
perturbations, for which one wants a stronger result than can be provided
by \thmref{etat_deriv} alone---we will require that the derivatives give
{\em uniformly good linear approximations} within bounded sets.
We address this question in \secref{differentiability}.

Let us remain with the general problem of inference on a parameter $\theta$. Fix
a base prior density, $\pbase(\theta)$, at which we have computed a VB
approximation.  Suppose we wish to ask what the variational optimum would have
been had we used some alternative prior density, $\palt(\theta)$.  Let us write
$\etaopt(\pbase)$ and $\etaopt(\palt)$ for these two approximations,
respectively.  To approximately answer this question using the local sensitivity
approach of \secref{local_sensitivity}, we must somehow define a continuous path
from $\pbase(\theta)$ to $\palt(\theta)$ parameterized, say, by $\t \in [0, 1]$.

There are many ways to do so.  For example, one might form the mixture
distribution:
%
\begin{align*}
%
\p_{lin}(\theta \vert \t) =
    (1- \t) \pbase(\theta) + \t \palt(\theta).
%
\end{align*}
%
Then $\p_{lin}(\theta \vert \t=0) = \pbase(\theta)$, $\p_{lin}(\theta \vert \t=1) =
\palt(\theta)$, and $\p_{lin}(\theta \vert \t)$ interpolates smoothly between the
two.  We could then attempt to apply \thmref{etat_deriv} using $\pstick(\nu \vert
\t)$ to compute $d\etaopt(\t) / d\t$, and approximate
%
\begin{align*}
%
\etaopt(\palt) \approx \etaopt(\pbase) + \fracat{d \etaopt(\t)}{d\t}{\t=1}(1 - 0).
%
\end{align*}
%
However, we might alternatively have defined the mixture in the log densities:
%
\begin{align*}
%
\log \p_{mult}(\theta \vert \t) =
    (1- \t) \log\pbase(\theta) + \t \log\palt(\theta) -
    \const. \\ \constdesc{\theta}
%
\end{align*}
%
Again, $\p_{mult}(\theta \vert \t=0) = \pbase(\theta)$, $\p_{mult}(\theta \vert
\t=1) = \palt(\theta)$, and $\p_{mult}(\theta \vert \t)$ interpolates smoothly
between the two.

Indeed, one may define a family of prior perturbations by adding the densities
after transforming pointwise by any invertible transformation, and then
transforming back into the original space.  We will consider (a generalization
of) the family of ``nonlinear'' functional perturbations given by
\citep{gustafson:1996:local}, of which our examples $\p_{lin}$ and $\p_{mult}$
are the two extremes, corresponding to $p=1$ and $p=\infty$, respectively.

Below, we will take $\lambda$ to denote the Lebesgue measure on the Borel sets
of $\thetadom \subseteq \mathbb{R}^{\thetadim}$.  We will be interested in
densities with respect to $\lambda$, expressed as Radon-Nikodym derivatives,
though it will be convenient to use the same notation for a density and for the
measure induced by the density.  Specifically, for a $\lambda$-measurable set
$S$, and a Radon-Nikodym derivative $f$ defined with respect to $\lambda$, we
will write $f(S) = \int_{\theta \in S} f(\theta) \lambda(d\theta)$.  Similarly,
for two densities $f$ and $g$, we will write $f \ll g$ to mean that $g(S) = 0
\Rightarrow f(S) = 0$ for all $\lambda$-measurable sets $S$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}\deflabel{prior_nl_pert}
%
Let $\mu$ denote a measure with $\mu \ll \lambda$, and fix $\pbase(\theta)$, a
density with respect to $\mu$.  Assume that $\pbase(\theta) > 0$ on $\thetadom$.
Let $p \in [1, \infty]$.  For any $\phi(\theta)$ for which the expressions are
well-defined, let
%
\begin{align*}
%
\rho(\theta \vert \phi) :={}& \begin{cases}
%
\pbase(\theta)^{1/p} + \frac{1}{p}\phi(\theta)
    & \textrm{when }p \in [1, \infty) \\
\pbase(\theta)\exp(\phi(\theta))
    & \textrm{when }p = \infty
%
\end{cases}\\
%
\tilde{\p}(\theta \vert \phi) :={}&
    \mathrm{sign}(\rho(\theta \vert \phi)) \abs{\rho(\theta \vert \phi)}^p.
%
\end{align*}
%
As usual, the normalized prior is given by
$\p(\theta \vert \phi) :=
    \tilde{\p}(\theta \vert \phi) /
         \int \tilde{\p}(\theta' \vert \phi) \mu(d\theta')$
when $0 < \int \tilde{\p}(\theta' \vert \phi) \mu(d\theta') < \infty$,
or is otherwise undefined.
%
\end{defn}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We have specified \defref{prior_nl_pert} in terms of the general function
$\phi(\theta)$ rather than an alternative prior density $\palt(\theta)$. Later,
this more general notation will allow us to embed our prior perturbations in a
vector space and analyze our linear approximations using tools from functional
analysis.  For the moment, however, we simply note that nothing has been lost,
since one can extrapolate to any alternative density $\palt(\theta)$ by taking
$\phi$ as given in the following definition.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{defn}\deflabel{prior_pert_class}
%
Fix the quantities in \defref{prior_nl_pert}.  Fix a density $\palt(\theta)$
with respect to $\mu$, with $\palt \ll \pbase$. For a given $\beta > 0$, let
%
\begin{align}
%
\phi(\theta | \beta, \palt) :={}
\begin{cases}
\beta \palt(\theta)^{1/p} - p \pbase(\theta)^{1/p}
    & \textrm{when }p \in [1, \infty) \\
\log \palt(\theta) - \log \pbase(\theta) + \log \beta
    & \textrm{when }p = \infty.
\end{cases} \eqlabel{phi_for_palt}
%
\end{align}
%
Similarly, define the set of $\phi$ that can be constructed from
valid priors as
%
\begin{align*}
%
\pertset := \bigg\{&
    \phi:  \phi(\theta | \beta, \palt) %\\&
    \textrm{ for some }\beta > 0\textrm{ and some density }\palt \ll \pbase
\bigg\}.
%
\end{align*}
%
Note that $\p(\theta \vert \t \phi(\cdot \vert \beta, \palt))$ equals $\pbase$
at $\t = 0$ and $\palt$ at $\t = 1$, so every valid prior is of the form
$\p(\theta \vert \phi)$ for some $\phi \in \pertset$.
%
\end{defn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{ex}\exlabel{zero_phi}
%
Taking $\palt = \pbase$, we have that $\phi = \phiz$ if and only if
$\beta = p$ for $p \in [1, \infty)$ or $\beta = 0$ for $p = \infty$.
For that reason it might make sense to restrict to $\beta = p$.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{phi_negative}
%
The perturbation $\phi(\theta)$ as given by \defref{prior_pert_class} can be
negative. Take $\thetadom = [0,1]$ and let $\pbase(\theta) = 1$. Let us choose a
$\palt(\theta)$ that shifts mass away from a small region next to zero.
Specifically, for  $\delta \in (0, 1)$ and $\epsilon \in (0, 1)$, let
%
\begin{align*}
%
\palt(\theta) :={}&
    \left(\frac{1-\delta \epsilon}{1 - \epsilon} \right)
        \ind{\epsilon \le \nu \le 1} +
    \delta \ind{0 \le \nu \le \epsilon}.
%
\end{align*}
%
% where the final approximation is due to the smallness of $\epsilon$.
Then \eqref{phi_for_palt} gives, for $p \in [0, \infty)$ and any $\beta > 0$,
%
\begin{align*}
%
\phi(\theta) ={}&
    \left( p \beta\left(\frac{1-\delta \epsilon}{1-\epsilon} \right)^{1/p}
        - 1
    \right)
        \ind{\epsilon \le \theta \le 1} +
    \left(p \beta \delta^{1/p} - 1 \right) \ind{0 \le \theta \le \epsilon}.
%
\end{align*}
%
When $\beta < \frac{1}{p} \delta^{-1/p}$, then $\phi(\theta)$ is negative for
$\theta \in (0, \epsilon)$.  Similarly, when $p = \infty$,
%
\begin{align*}
%
\phi(\theta) ={}&
    \ind{\epsilon \le \nu \le 1}
        \log \left(\frac{1-\delta \epsilon}{1 - \epsilon} \right) +
    \ind{0 \le \nu \le \epsilon} \log \delta + \log \beta,
%
\end{align*}
%
so $\phi(\theta)$ is negative for $\theta \in (0, \epsilon)$ when
$\beta < \delta$.

Note that, in this example, one could choose $\beta$ sufficiently large that
$\phi(\theta)$ is non-negative everywhere, but at the cost of making
$\phi(\theta)$ large on $\theta \in (\epsilon, 1)$.   See \appref{positive_pert}
for more discussion of this point.

\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{ex}\exlabel{phi_necessarily_negative}
%
It is not always possible to choose $\beta$ large enough to guarantee positive
$\phi(\theta)$. For example, again take $\thetadom=[0,1]$, and let
%
\begin{align*}
%
\pbase(\theta) ={} 2 \theta^{-1/2} \mathand
\palt(\theta) ={} 1.
%
\end{align*}
%
Then
%
\begin{align*}
%
\phi(\theta) ={}&
\begin{cases}
        p\beta - 2 \theta^{-1/2} & \textrm{for }p \in [0, \infty) \\
        \frac{1}{2} \log \theta + \log 2 + \log \beta
            & \textrm{for }p = \infty
\end{cases}.
%
\end{align*}
%
For this perturbation, $\inf_\theta \phi(\theta) = -\infty$ irrespective
of $p$ or $\beta$, and no choice of $\beta$ can induce a change from
$\pbase$ to $\palt$ with a positive $\phi(\theta)$.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}
%
Take $\thetadom = [0,1]$.  The pair $\pbase(\theta)  = \frac{1}{2}\ind{\theta <
1/2}$ and $\palt(\theta) = \frac{1}{2} \ind{\theta > 1/2}$ are disallowed by
\defref{prior_pert_class} because we do not have $\palt \ll \pbase$.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In order to approximate the effect of replacing $\pbase$ with $\palt$, we can
choose a $p$, choose a $\beta$, compute the corresponding $\phi(\cdot \vert
\beta, \palt)$ using \defref{prior_nl_pert}, and apply \thmref{etat_deriv} with
$\p(\theta \vert \t) = \p(\theta \vert \t \phi(\cdot \vert \beta, \palt))$.
To do so, we will require that \assuref{dist_fun_nice} holds with
$\psi(\theta, \t) = \log \p(\theta \vert \t \phi(\cdot \vert \beta, \palt))$.
Plugging in \defref{prior_nl_pert}, we see that
%
%
\begin{align}
%
\logp(\theta \vert \t \phi) - \log \pbase(\theta) ={}&
\begin{cases}
    \log\left(1 + \t \frac{\phi(\theta)}{\pbase(\theta)^{1/p}}\right)
    & \textrm{when }p \in [1, \infty) \\
    \t \phi(\theta)
    & \textrm{when }p = \infty
%
\end{cases}  \eqlabel{nl_vb_pert_p}\\
%
\fracat{\partial \log \p(\theta \vert \t)}{\partial \t}{\t=0} ={}&
\begin{cases}
   \frac{\phi(\theta)}{\pbase(\theta)^{1/p}}
   & \textrm{when }p < \infty \\
   \phi(\theta)
   & \textrm{when }p = \infty.
\end{cases}\eqlabel{nl_vb_pert_pinf}
%
\end{align}
%
It turns out that the derivative takes the form of an integral against
$\phi$, as we state in the following corollary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{cor}\corlabel{etafun_deriv_form}
%
Let \assuref{kl_opt_ok} hold at $\eta_0 = \etaopt$.
%
Fix $p$ and the quantities given in \defref{prior_nl_pert}, and let $g(\eta):
\etadom \mapsto \mathbb{R}$ denote a continuously differentiable real-valued
function of interest.  Define the influence function
%
\begin{align}\eqlabel{infl_defn}
%
\infl_p(\theta) :={}&
% \begin{cases}
    - \fracat{d g(\eta)}{ d \eta^T}{\etaopt} \hessopt^{-1}
        \lqgradbar{\theta \vert \etaopt}
        \frac{\q(\theta \vert \etaopt)}{\pbase(\theta)^{1/p}},
% & \textrm{when }p \in [1, \infty) \\
%
%     - \fracat{d g(\eta)}{ d \eta^T}{\etaopt} \hessopt^{-1}
%         \lqgradbar{\theta \vert \etaopt}
%         \q(\theta \vert \etaopt).
% & \textrm{when }p = \infty
%
% \end{cases}
%
\end{align}
%
where we take $\pbase(\theta)^{1/p}=1$ when $p = \infty$.

Let the variational densities $\q(\theta \vert \eta)$ satisfy
\assuref{dist_fun_nice} for $\t_0 = 0$ with both $\psi(\theta, \t) \equiv 1$ (no
$\theta$ dependence) and with and $\psi(\theta, \t) = \log \p(\theta \vert \t
\phi)$. Then the map $\t \mapsto g(\etaopt(\t \phi))$ is continuously
differentiable at $\t=0$ with derivative
%
\begin{align}\eqlabel{vb_eta_infl_sens}
%
\fracat{d g(\etaopt(\t \phi))}{d \t}{0} ={}&
    \int \infl_p(\theta) \phi(\theta) \mu(d\theta).
%
\end{align}
%
\begin{proof}
%
This follows immediately from \thmref{etat_deriv}, \eqref{nl_vb_pert_p}, and
\eqref{nl_vb_pert_pinf}.
%
\end{proof}
%
\end{cor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{ex}\exlabel{phi_for_beta}
%
Take $\pbase(\theta) = \betadist{\theta \vert 1, \alpha_0}$ and $\palt(\theta) =
\betadist{\theta \vert 1, \alpha_1}$.  Then $\thetadom=[0,1]$, and we can let
$\mu$ be the Lebesgue measure on $[0,1]$, so
%
\begin{align*}
%
\pbase(\theta) ={}&
    \frac{\Gamma(\alpha_0)}{\Gamma(1 + \alpha_0)} (1 - \theta)^{\alpha_0 - 1}.
%
\end{align*}
%
Then, for $p = 1$,

\begin{align}\eqlabel{phi_beta_p1}
%
\phi(\theta \vert \beta, \palt) ={}&
    p \beta \frac{\Gamma(\alpha_1)}{\Gamma(1 + \alpha_1)}
        (1 - \theta)^{\alpha_1 - 1} -
    \frac{\Gamma(\alpha_0)}{\Gamma(1 + \alpha_0)}
        (1 - \theta)^{\alpha_0 - 1}.
%
\end{align}
%
Note that, when $\t = 1$, the normalizing constant and $\beta$ cancel in the
normalization of $\p(\theta \vert \t \phi)$:
%
\begin{align*}
%
\p(\theta \vert \phi(\theta \vert \beta, \palt)) =
\frac{p \beta \frac{\Gamma(\alpha_1)}{\Gamma(1 + \alpha_1)}
        (1 - \theta)^{\alpha_1 - 1}}
     {p \beta \frac{\Gamma(\alpha_1)}{\Gamma(1 + \alpha_1)}
       \int_0^1 (1 - \theta')^{\alpha_1 - 1} \lambda(d\theta')}
=
\frac{(1 - \theta)^{\alpha_1 - 1}}
     {\int_0^1 (1 - \theta')^{\alpha_1 - 1} \lambda(d\theta')}.
%
\end{align*}
%
For this reason, we are free to choose $\beta > 0$ in \defref{prior_pert_class}
and still extrapolate to the same $\palt$ when $\t = 1$.

\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{ex}\exlabel{phi_for_beta_pinf}

When $p = \infty$,
%
\begin{align}
%
\phi(\theta \vert \beta, \palt) ={}&
    \log \left(
        \frac{\Gamma(\alpha_1) }{\Gamma(1 + \alpha_1)}
    \right)  + (\alpha_1 - 1) \log (1 - \theta) - \nonumber\\
{}&
    \log \left(
        \frac{\Gamma(\alpha_0)}{\Gamma(1 + \alpha_0)}
    \right) + (\alpha_0 - 1) \log (1 - \theta)  + \log \beta \nonumber\\
={}&
\log \left(
    \frac{\Gamma(\alpha_1) }{\Gamma(1 + \alpha_1)}
\right) -
\log \left(
    \frac{\Gamma(\alpha_0)}{\Gamma(1 + \alpha_0)}
\right) + \log \beta + (\alpha_1 - \alpha_0) \log(1 - \theta).
\eqlabel{phi_beta_pinf}
%
\end{align}
%
For $p = \infty$, the normalizing constant and $\beta$ cancel for all $\t$:
%
\begin{align*}
%
\p(\theta \vert \t \phi(\theta \vert \beta, \palt)) ={}&
\frac{  \beta \frac{\Gamma(\alpha_1) \Gamma(1 + \alpha_0) }
                   {\Gamma(1 + \alpha_1) \Gamma(\alpha_0)}
        (1-\theta)^{\alpha_0 (1 - \t) + \alpha_1 \t}
    }
    {
        \beta \frac{\Gamma(\alpha_1) \Gamma(1 + \alpha_0) }
                   {\Gamma(1 + \alpha_1) \Gamma(\alpha_0)}
             \int_0^1 (1-\theta')^{\alpha_0 (1 - \t) +
                                   \alpha_1 \t} \lambda(d\theta')
     }
\\={}&
\frac{(1-\theta)^{\alpha_0 (1 - \t) + \alpha_1 \t}}
     {\int_0^1 (1-\theta')^{\alpha_0 (1 - \t) + \alpha_1 \t} \lambda(d\theta')}.
%
\end{align*}
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{gem_fun_pert}
%
Let us apply \corref{etafun_deriv_form} to the GEM stick-breaking priors with
$p=1$, following \exref{phi_for_beta}.  In order  to use
\lemref{normal_q_is_regular}, it will be helpful to express the priors
in the logit stick space as in \exref{gem_pert_ok}.  We thus take
$\theta = \lnuk$, $\thetadom = \mathbb{R}$, and...
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
