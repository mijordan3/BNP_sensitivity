In this section, we show how to find worst-case functional perturbations to the
stick form. In particular, we start by  to motivating an norm measuring the size
of a functional perturbation $\phi$. We then show how to compute an influence
function to summarize the effect of different choices of $\phi$. We prove that,
for multiplicative perturbations and the $\infty$-norm, the linear approximation
is uniformly good. Finally, we show that this uniformly good approximation is
unique among many alternative choices of functional perturbation.

% %
% \noindent \textbf{An infinity norm.}
% First, we define $\norminf{\cdot}$ and a corresponding ball.
% Let $\mu$ be a probability measure on $[0,1]$. Then
% \begin{equation} \eqlabel{infty_norm}
% 	\norminf{\phi} := \esssup_{\nu_0 \sim \mu} \abs{\phi(\nu_0)},
% 	\quad \ball_\phi(\delta) := \left\{ \phi: \norminf{\phi} <
% \delta \right\}.
% \end{equation}
% %
%%
\noindent \textbf{The influence function.}
%
Next we define the influence function $\infl$ and discuss its usefulness for
understanding the effect of functional perturbations $\phi$.
\todo{The experiments use $\mathbb{R}$ as the space, not $[0,1]$.  So it
would be good to be explicit about the densitites.}
%
\begin{cor}\corylabel{etafun_deriv_form_stick}
%
Under the conditions of \thmref{bnp_deriv}, with $\norminf{\phi} < \infty$ and
$\varepsilon = \t$, let $\g(\eta): \etadom \mapsto \mathbb{R}$ denote a
continuously differentiable real-valued function of interest.  Define the
\emph{influence function} $\infl: [0,1] \mapsto \mathbb{R}$:
%
\begin{align} \eqlabel{infl_defn_bnp}
%
\infl(\cdot) :={}&
    - \sum_{k=1}^{\kmax-1} \fracat{d g(\eta)}{ d \eta^T}{\etaopt} \hessopt^{-1}
        \lqgradbark{\cdot \vert \etaopt}
        \qk(\cdot \vert \etaopt),
%
\end{align} where $\lqgradbark{\cdot \vert \etaopt}$ and $\qk(\cdot \vert
\etaopt)$ replace $\q(\zeta \vert \eta)$ with just the factor of $\q$ for
$\nu_k$.
%
Then the derivative \eqref{bnp_vb_eta_sens} can be written as
%
\begin{align} \eqlabel{vb_eta_infl_sens_bnp}
%
\fracat{d \g(\etaopt(\t))}{d \t}{0} ={}&
    \int_0^1 \infl(\nu_0) \phi(\nu_0) d\nu_0.
%
\end{align}
\end{cor}
%
\begin{proof}
%
The form of the influence function is given by gathering terms in
\eqref{bnp_vb_eta_sens} and re-writing the variational expectation as an
integral over $[0,1]$. We establish an analogous general result for mean-field
VB approximations in \coryref{etafun_deriv_form} of
\appref{diffable_nonparametric}, specializing to the BNP case in
\exref{infl_univariate} of \appref{diffable_nonparametric}.
%
\end{proof}

Although we will shortly use the influence function to find the formal
worst-case choice of $\phi$, we can also use the influence function to
informally choose influential prior perturbations. In our experiments in
\secref{results}, we show how to do this by choosing $\phi$ that align with
particularly high-magnitude positive or negative values of the influence
function; this alignment will ensure a large positive or negative gradient and
hence a large change.

%%
\noindent \textbf{Worst-case functional perturbations.}
%
With \coryref{etafun_deriv_form_stick} in hand, we can find the worst-case
choice of $\phi \in \ball_\phi(\delta)$.

\LinfExamplesFig{}

First, we find the VB analogue of \citet[Result 11]{gustafson:1996:local}.
Second, we justify using the influence function for finding the worst case by
establishing uniform quality of the linear approximation for sufficiently small
$\ball_\phi(\delta)$.

\begin{cor}\corylabel{etafun_worst_case_stick}
%
Under the conditions of \coryref{etafun_deriv_form_stick},
%
\begin{align*}
%
\sup_{\phi \in \ball_\phi(\delta)}
    \fracat{d g(\etaopt(\t))}{d \t}{0} =
        \delta \int \abs{\infl(\nu_0)} \mu(d\nu_0),
%
\end{align*}
%
and the supremum is achieved at the perturbation
$\phi^*(\cdot) = \delta \, \mathrm{sign}\left(\infl(\cdot)\right)$.
%
\end{cor}
%
\begin{proof}
%
The result follows immediately from applying H{\"o}lder's inequality to
\eqref{vb_eta_infl_sens_bnp}. We establish a similar but much more general
result for mean-field VB approximations with general choices of model and
parameters in \coryref{etafun_worst_case} of \appref{diffable_worst_case}. The
present result is a special case using \exref{infl_univariate} of
\appref{diffable_worst_case}.
%
\end{proof}

To justify using linear approximations to explore the unit ball
$\ball_\phi(\delta)$ and find the worst case, we require a stronger result than
\coryref{etafun_deriv_form}. In particular, \coryref{etafun_deriv_form} states
only that, for a {\em particular} direction $\phi$, $\t \mapsto \etaopt(\t)$ is
continuously differentiable.  Since $\t \phi \in \ball_\phi(\t \norminf{\phi})$,
\coryref{etafun_deriv_form} implies only that, for a fixed $\phi$, one can make
$\t$ sufficiently small so that the error $\abs{\etaopt(\t) - \etalin(\t)}$ goes
to zero faster than $\t$. But, if we write $\etaopt(\t\phi)$ and $\etalin(\t
\phi)$ to make the dependence on $\phi$ explicit, then
\coryref{etafun_deriv_form} does not imply that, for a fixed $\delta$ (no matter
how small), the worst-case error $\sup_{\phi \in \ball_\phi(\delta)}
\abs{\etaopt(\phi) - \etalin(\phi)}$ is bounded, much less that it goes to zero
faster than $\delta$.

To be able to apply \coryref{etafun_worst_case} to find the worst-case
perturbation $\phi$, we need to establish that the approximation is sufficiently
good over all $\phi$ of interest. Observe that $\phi$ is a member of the Banach
space $L_\infty$ \citep[Theorem 5.2.1]{dudley:2018:real}.  We require that the
map $\phi \mapsto \etaopt(\phi)$, which maps $L_\infty$ to $\mathbb{R}^\etadim$,
admits a uniformly good linear approximation amongst $\phi \in
\ball_\phi(\delta)$. In other words, we require $\phi \mapsto \etaopt(\phi)$ to
be Fr{\'e}chet differentiable, as we now formally define.

\begin{defn}\deflabel{diffable_classes}
    (Fr{\'e}chet differentiability,
    \citep[Definition 4.5]{zeidler:2013:functional})
%
Let $B_1$ and $B_2$ denote Banach spaces, and let $\ball_1 \subseteq B_1$ define
an open neighborhood of $\phi_0 \in B_1$.
%
A function $f: \ball_1 \mapsto B_2$ is {\em Fr{\'echet} differentiable} (also
known as boundedly differentiable) at $\phi_0$ if there exists a  bounded linear
operator, $f^{\mathrm{lin}}: B_1 \mapsto B_2$, such that
%
\begin{align*}
%
\lim_{t \rightarrow 0}
    \sup_{\phi: \norm{\phi - \phi_0} = 1}
    \frac{f(\phi) - f(\phi_0) -
          f^{\mathrm{lin}}(t (\phi - \phi_0))
         }{t} \rightarrow 0.
%
\end{align*}
%
\end{defn}

By \citep[Proposition 4.8]{zeidler:2013:functional}, if a function is
Fr{\'e}chet differentiable, then the linear operator $f^{\mathrm{lin}}$ is given
precisely by the directional derivative $d f(t (\phi - \phi_0)) / d t$. Thus, if
$\phi \mapsto \etaopt(\phi)$ is Fr{\'e}chet differentiable, its derivative is
given by \coryref{etafun_deriv_form}.  Fr{\'e}chet differentiability guarantees
that the error of the linear approximation given by \coryref{etafun_deriv_form}
does not blow up in the ball $\ball_\phi(\delta)$.

We emphasize that Fr{\'e}chet differentiability is neither sufficient nor
necessary for a derivative to be useful.  For example, it is possible in
principle for a function to be Fr{\'e}chet differentiable but still have a very
large finite second derivative, and so fail to extrapolate meaningfully to any
alternatives one cares about.  Conversely, if a function fails to be Fr{\'e}chet
differentiable, the derivative may still perform well in particular directions,
including that chosen by \coryref{etafun_worst_case}.  Nevertheless, Fr{\'e}chet
differentiability is a strong local result, and provides some assurance that one
can use results such as \coryref{etafun_worst_case} without uncovering
pathological behavior.

Finally, then, we prove that our perturbation here is Fr{\'e}chet differentiable.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thm}\thmlabel{eta_phi_deriv_stick}
%
Under the conditions of \thmref{bnp_deriv}, the map $\phi \mapsto \etaopt(\phi)$
is well-defined and continuously Fr{\'e}chet differentiable in a neighborhood of
the zero function as a map from $\linf$ to $\mathbb{R}^\etadim$,
with the derivative given in \coryref{etafun_deriv_form}. \end{thm}
%
\begin{proof}
%
Our result here is a special case of a general result for VB approximations
based on KL divergence given in \thmref{eta_phi_deriv} of
\appref{diffable_worst_case}.
%
\end{proof}

%%
\noindent \textbf{Many other functional perturbations and norms are not Fr{\'e}chet differentiable.}
%
So far we have focused on the multiplicative functional perturbations in
\eqref{mult_perturbation} combined with the infinity norm in \eqref{infty_norm}.
We now ask whether we could perform a similar analysis for other functional
perturbations. We show that, of the perturbations proposed by
\citet{gustafson:1996:local}, only multiplicative perturbations yield
Fr{\'e}chet differentiable VB optima.

Specifically, \citet{gustafson:1996:local} examines general perturbations, from
initial prior $\pbase$ to alternative $\palt$, that take the following form --
with $\theta$ a parameter $\theta \in \thetadom \subseteq
\mathbb{R}^{\thetadim}$ and $p \in [1, \infty)$:
%
\begin{align}\eqlabel{p_pert_simple_bnp}
%
\ptil(\theta \vert \tp) :=
    \left((1 - \tp)\pbase(\theta)^{1/p} +
    \tp \frac{1}{p}\palt(\theta)^{1/p} \right)^{p}.
%
\end{align}
%
Again, let $\phi$ represent the perturbation size, now with:
%
\begin{align}\eqlabel{phi_lp_norm_bnp}
%
\phi(\theta \vert \palt, p) :={}
    \palt(\theta)^{1/p} - \pbase(\theta)^{1/p} \mathand
\norm{\phi}_p :={} \left(\int \abs{\phi(\theta)}^p \right)^{1/p}.
%
\end{align}
%
The limit $p \rightarrow \infty$ recovers our multiplicative perturbation in
\eqref{mult_perturbation} with infinity norm in \eqref{infty_norm}. The choice
$p=0$ recovers a purely additive perturbation.

Our next theorem shows that the KL is discontinuous for $p < \infty$.
Since Fr{\'e}chet differentiability implies continuity \citep[Proposition 4.8
(d)]{zeidler:2013:functional}, \thmref{kl_discontinuous} implies that it is
impossible to derive an analogue of \thmref{eta_phi_deriv} for perturbations of
the form \eqref{p_pert_simple_bnp} with the norms \eqref{phi_lp_norm_bnp}.
%
\begin{thm}\thmlabel{kl_discontinuous_main}
%
Let $\mu$ denote a measure on $\thetadom$ that is absolutely continuous with
respect to the Lebesgue measure, and let $\q(\theta)$ and $\pbase(\theta)$
denote densities with respect to $\mu$.  Without loss of generality, assume that
$\q(\theta) > 0$ on $\thetadom$.  Assume that $\KL{\q(\theta) ||
\pbase(\theta)}$ is well-defined and finite.

Then, for any $\epsilon > 0$ and any $M > 0$, we can find a density
$\palt(\theta)$ such that $\norm{\phi(\theta \vert \palt, p)}_p < \epsilon$ but
$\abs{\KL{q(\theta) || \palt(\theta)} - \KL{q(\theta) || \pbase(\theta)}} > M$.
%
\end{thm}
%
See \appref{diffable_lp} for a proof.
% \thmref{kl_discontinuous}

Recall from \secref{local_sensitivity} (and \exref{beta_inf_norm} of
\appref{diffable_nonparametric}) that there exist priors that cannot be formed
from \eqref{mult_perturbation} using $\phi$ with $\norminf{\phi} < \infty$. In
light of the proof of \thmref{kl_discontinuous_main}, the limited expressiveness
of multiplicative perturbations with the $\norminf{\cdot}$ norm looks like a
feature rather than a bug.
% The KL divergence that defines a variational objective cannot handle
% prior densities that are too close to zero.  The $\norminf{\cdot}$ norm
% considers such densities to be ``distant'' from $\pbase$, whereas the
% more permissive $\norm{\cdot}_p$ norms do not.
Consider \figref{linf_examples}, which illustrates the tradeoffs between the
various norms.  The two blue and red densities are far from one another
according to KL divergence since the red density takes values that are nearly
zero where the blue density has nonzero mass. They are also distant in
$\norminf{\cdot}$ since it takes a large multiplicative change to turn the
nonzero blue density into the nearly zero red density. However, the two
densities are close in $\norm{\cdot}_{p}$ since the region where the red density
is nearly zero has a small measure. In order for VB approximations to be
continuous (a necessary condition for Fr{\'e}chet differentiability), one must
consider a topology on priors that is no coarser than the topology induced by KL
divergence.  But since valid priors can take values close to zero, a sacrifice
in expressiveness of the neighborhood of zero must be made in order to induce a
topology that works with KL divergence. Multiplicative changes and the
$\norminf{\cdot}$ norm make such a tradeoff in a natural, easy-to-understand
way.

%\FunctionDistFig{}

In this sense, VB approximations based on KL divergence are inherently
non-robust to priors that ablate mass nearly to zero.  No parameterization of
the space of priors will relieve this non-robustness.  Only by basing
variational approximations on divergences other than KL will this non-robustness
be alleviated.
