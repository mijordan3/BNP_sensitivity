
When, then, is $\etaopt(\t)$ continuously differentiable?  We will now state
some sufficient conditions under which we can apply the implicit function
theorem (e.g., \citet{krantz:2012:implicit}) to prove the continuous
differentiability of $\etaopt(\t)$.

The first key assumption, \assuref{dist_fun_nice}, states sufficient conditions
for which we can apply the dominated convergence theorem to variational
expectations of some generic function $\psi(\theta, \t)$, allowing us to
translate continuity of the variational and model densitites into continuity of
the variational objective.  The details can be found in \lemref{logq_derivs,
logq_continuous} of \appref{cont_lemmas}.
%
In case \assuref{dist_fun_nice} seems forbidding, observe that, in lieu of
\assuref{dist_fun_nice} we might equivalently have said that we can exchange
limits and variational expectations whenever needed.  \Assuref{dist_fun_nice} is
simply a precise catalogue of what is needed.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{lem}
% %
% Under \assuref{dist_fun_nice}, we can exchange the order of integration
% and differentiation in
% %
% \begin{align*}
% %
% \fracat{\partial\expect{\q(\theta \vert \eta)}{\psi(\theta, \t)}}
%        {\partial\eta}{\etaopt, \t=0}
% \textrm{, }
% \fracat{\partial^2\expect{\q(\theta \vert \eta)}{\psi(\theta, \t)}}
%        {\partial\eta \partial\eta}{\etaopt, \t=0}
% \textrm{, and }
% \fracat{\partial^2\expect{\q(\theta \vert \eta)}{\psi(\theta, \t)}}
%        {\partial\eta \partial \t}{\etaopt, \t=0}.
% %
% \end{align*}
% %
% (See also \lemref{logq_derivs, logq_continuous} of \appref{cont_lemmas}
% for a more detailed statement.)
% %
% \end{lem}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%


% Finally, in \assuref{q_stick_regular} we draw the needed connection between the
% class of prior perturbations and the variational approximation.
%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{assu}\assulabel{q_stick_regular}
% %
% Under \defref{prior_t}, assume that the variational densities $\q(\theta \vert
% \eta)$ satisfy \assuref{dist_fun_nice} with both $\psi(\theta, \t) \equiv 1$ (no
% $\theta$ dependence) and with and $\psi(\theta, \t) = \log \p(\theta \vert \t) -
% \log \p(\theta \vert \t=0)$.
% %
% \end{assu}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


We conclude this section by showing that \thmref{etat_deriv} applies to the
setting of BNP stick-breaking.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lem}\lemlabel{normal_q_is_regular}
%
In the setting of \assuref{dist_fun_nice}, let $\theta \in \mathbb{R}$, let
$\mu$ be the Lebesgue measure, and let $\q(\theta \vert \eta) = \normdist{\theta
\vert \eta}$ be a normal distribution parameterized by its natural exponential
family parameters.

Let $\sigma(\eta)$ denote the standard deviation of the normal distribution.
Fix $\eta_0$ such that $\sigma(\eta_0) > 0$, and let $\ball_\eta$ be an open set
containing $\eta_0$ such a that $\sigma_{max} := \sup_{\eta \in \ball_\eta}
\sigma(\eta) < \infty$.

If there exists a neighborhood $\ball_\t$ of $\t_0$ such that $\abs{\psi(\theta,
\t)}$ and $\abs{\psigrad{\theta, \t}}$ are uniformly bounded by some multiple of
$\exp(-\abs{\theta})$ for all $\t \in \ball_\t$, then $\q$ and $\psi$ satisfy
\assuref{dist_fun_nice}.

\begin{proof}
%
By properties of the exponential family,
%
\begin{align*}
%
\lqgrad{\theta, \eta} ={} (\theta, \theta^2)^T \mathand&
\lqhess{\theta, \eta} ={} 0_{2\times2} \Rightarrow\\
%
\norm{\lqgrad{\theta, \eta}}_2^2 ={} \theta^2 + \theta^4 \mathand&
\norm{\lqhess{\theta, \eta}}_2 ={} 0.
%
\end{align*}
%
Let $\ballclosed_\eta$ denote the closure of $\ball_\eta$, and let
%
\begin{align*}
%
\eta^* := \argmax_{\eta \in \ballclosed_\eta}
    \expect{\q(\theta \vert \eta)}{\exp(\abs{\theta})}.
%
\end{align*}
%
By standard properties of the normal and the boundedness of $\sigma(\eta)$, the
right hand side of the preceding display is finite.
%
Then
%
\begin{align*}
\int \q(\theta \vert \eta) \psi(\theta, \t) \mu(d \theta) \le{}&
    \left( \sup_{\theta} \sup_{\t \in \ball_\t}
        \abs{\psi(\theta, \t)} \exp(-\abs{\theta}) \right)
    \int \q(\theta \vert \eta) \exp(\theta) \mu(d \theta)
%
\\\le{}&
    \const
    \expect{\q(\theta \vert \eta^*)}{\exp(\abs{\theta})}.
    \quad\constdesc{\eta, \t}
%
\end{align*}
%
Therefore, for \assuitemref{dist_fun_nice}{fundom}, we can take $M(\theta)
\propto \q(\theta \vert \eta^*) \exp(\abs{\theta})$. The other terms follow
similarly, since each multiplier of $\q(\theta \vert \eta)$ is dominated by
$\exp(-\abs{\theta})$.  The final $M(\theta)$ simply takes the largest
of the five constants.
%
\end{proof}
%
\end{lem}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{gem_pert_ok}
%
To analyze \exref{alpha_perturbation}, we take $\theta$
in \lemref{normal_q_is_regular}
be the unconstrained stick-breaking proportion $\lnuk$, which
recall from \secref{stick_expectations}
was normally distributed under $\q$.
Let $\mu$ be the Lebesgue measure on $\mathbb{R}$.

In \exref{alpha_perturbation},
the parameterization of the stick-breaking distribution was given by
\begin{align*}
  \log \pstick(\nuk \vert \t) - \log \pstick(\nuk \vert \t=0) ={}&
  \t \log(1 - \nuk).
\end{align*}
%
Expressing the perturbation in terms of
$\lnuk$,
%
\begin{align*}
%
\log \pstick(\lnuk \vert \t) - \log \pstick(\lnuk \vert \t=0) ={}&
\t \log\left(1 - \frac{\exp(\lnuk)}{1 + \exp(\lnuk)}\right)
\\={}&
-\t \log\left(1 + \exp(\lnuk)\right).
%
\end{align*}
%
So, by \lemref{normal_q_is_regular}, \assuref{q_stick_regular} is satisfied with
the VB approximation given in \secref{stick_expectations} and the parametric
perturbation given in \exref{alpha_perturbation}.
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{cor}\corlabel{gem_approximation_ok}
%
For the variational approximation of \secref{model_vb} and perturbation
given in \exref{alpha_perturbation}, $\alpha \mapsto \etaopt(\alpha)$
is continuously differentiable.
%
\begin{proof}
%
We have already shown in \exref{gem_pert_ok} that \assuref{q_stick_regular} is
satisfied.  Given that the variational approximations to $\p(\z \vert \x, \beta,
\nu)$ and $\p(\beta \vert \x, \nu, \z)$ are conjugate exponential family
approximations, $\eta \mapsto \KL{\eta, 0}$ is continuous.  It remains only to
numerically find $\etaopt$ and verify \assuitemref{kl_opt_ok}{kl_hess}, i.e.
that the Hessian is positive definite at the optimum.
%
\end{proof}
%
\end{cor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% We conclude this section with a brief remark about computing the expectation
% $\crosshessian$ in our BNP sensitivity analysis.
% We are interested in sensitivity to the stick-breaking distribution,
% so only the prior terms on stick-breaking proportions
% $\nu = (\nu_1, ..., \nu_{\kmax - 1})$ depends on $t$.
% Because the elements of $\nu$ fully factorize
% under both the prior and the variational distributions,
% $\crosshessian$ decomposes as
% \begin{align}
%   \crosshessian &=
%   \sum_{\k=1}^{\kmax - 1}
%           \expect{\q(\nuk \vert \eta)}
%                  {
%                  \lqgrad{\nuk \vert \etaopt}
%                  \fracat{\log \pstick(\nuk \vert \t)}{\partial \t}{\t = 0}
%                  } \notag\\
%   &= \sum_{\k=1}^{\kmax - 1}
%          \evalat{\nabla_\eta \expect{\q(\nuk \vert \eta)}
%                 {
%                 \fracat{\log \pstick(\nuk \vert \t)}{\partial \t}{\t = 0}
%                 }}{\eta = \etaopt(0)},
% \eqlabel{sens_mixed_partial}
% \end{align}
% where we assumed that $\q(\theta \vert \eta)$ is normalized, so
% $\lqgradbar{\theta \vert \etaopt} = \lqgrad{\theta \vert \etaopt}$,
% and that the assumptions of \thmref{etat_deriv} hold, so we
% can freely exchange derivatives with expectations.
%
% We approximate the expectation using GH quadrature (\eqref{gh_integral}),
% with
% $f(\nu_k) = \fracat{\log \pstick(\nuk \vert \t)}{\partial \t}{\t = 0}$.
% In all the functional forms for
% $\t \mapsto \pstick(\nuk \vert \t)$ considered below,
% $f(\nu_k)$ can be provided in either closed-form or computed with automatic differentiation.
% The resulting GH approximation is a deterministic function of $\eta$,
% and thus the gradient in \eqref{sens_mixed_partial} can be computed
% with another application of automatic differentiation.
% Note that $\crosshessian$ is sparse in \eqref{sens_mixed_partial}:
% it is zero for all entries of
% $\eta$ other than those that parameterize the sticks.
