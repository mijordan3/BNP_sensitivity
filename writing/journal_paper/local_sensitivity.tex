We now turn to the optimization problem \eqref{vb_optimization} where the priors
$\pstick(\nuk)$ which enter the term $\logp(\zeta)$ depend on a real-valued
parameter, $\t \in \tdom \subseteq \mathbb{R}$, writing $\pstick(\nuk \vert
\t)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{alpha_perturbation}
%
When drawing from the classical $\mathrm{GEM}(\alpha)$ distribution, we
model
%
\begin{align*}
%
\pstick(\nuk \vert \alpha) ={}&
    \betadist{\nuk \vert 1, \alpha} \Rightarrow\\
\log \pstick(\nuk \vert \alpha) ={}&
    (\alpha - 1) \log(1 - \nuk) + \const. &
    \constdesc{\nuk}
%
\end{align*}
%
Fix some ``original'' $\alpha_0$.  In this case, we represent deviations from
the choice $\alpha_0$ by identifying $\t$ with $\alpha - \alpha_0$:
%
\begin{align}\eqlabel{gem_alpha_pert}
%
\log \pstick(\nuk \vert \alpha) ={}&
    (\alpha + \alpha_0 - 1) \log(1 - \nuk) + \const.
    %& \constdesc{\nuk}
%
\end{align}
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Since the posterior in turn depends on the prior parameter $\t$, which we write
$\p(\zeta \vert \x, \t)$. The $\t$ dependence propagates further to the optimal
variational parameters as well through the dependence of the KL divergence on
$\t$.  Define the shorthand notation
%
\begin{align}\eqlabel{kl_shorthand}
%
\KL{\eta, \t} := \KL{\q(\zeta \vert \eta) || \p(\x \vert \zeta, \t)}
\mathand
\etaopt(\t) := \argmin_{\zeta \in \etadom} \KL{\eta, \t},
%
\end{align}
%
where we write $\etaopt(\t)$ to emphasize the dependence of the optimum on $\t$.
Without loss of generality, we will continue to use $\etaopt$ with no argument
to refer to $\etaopt(0)$.  That is, we take $\t = 0$ at the ``original''
problem, \eqref{vb_optimization}.

If the map $\t \mapsto \etaopt(\t)$ is continuously differentiable, and we have
already computed the solution $\etaopt$ to the ``original'' problem
\eqref{vb_optimization}, then we can form a Taylor series approximation to
$\etaopt(\t)$.  Specifically, we define
%
\begin{align}\eqlabel{etalin_def}
%
\etalin(\t) := \etaopt + \fracat{d \etaopt(\t)}{d \t}{\t=0} \t .
%
\end{align}
%
Evaluating $\etaopt(\t)$ requires solving a new optimization problem, but, given
$d\etaopt(\t) / d\t | 0$, evaluating $\etalin(\t)$ involves only
multiplication and addition.  When $|\t|$ is small, by continuous
differentiability of $\etaopt(\t)$, we might hope that $\etaopt(\t) \approx
\etalin(\t)$, and so we can use $\etalin(\t)$ to quickly approximate a
time-consuming optimization problem.

Futhermore, or functions of interest $\g(\eta)$ which are themselves
differentiable, we can use the chain rule to compute
%
\begin{align}\eqlabel{vb_g_sens}
%
\fracat{d g(\etaopt(\t))}{d\t} ={}&
    \fracat{\partial g(\eta)}{\partial \eta^T}{\etaopt(\t_0)}
    \fracat{d \etaopt(\t)}{d \t}{\t_0} \\
\glin(\t) :={}& \g(\etaopt(\t_0)) + \fracat{d g(\etaopt(\t))}{d\t}{\t_0} (\t - \t_0).
%
\end{align}
%
For non-differentiable functions of $\eta$, we can still form the approximation
%
\begin{align*}
%
\gapprox(\t) :={}& \g(\etalin(\t)).
%
\end{align*}
%
The advantage of $\glin(\t)$ relative to $\gapprox(\t)$ is that for the former
we can compute influence functions and worst-case perturbations, as we discuss
below in \secref{prior_perturbations}.  Converse, $\gapprox(\t)$ may be expected
to provide a better approximation in some cases since it retains non-linearities
in the map $\eta \mapsto \g(\eta)$, linearizing only the computationally
intensive map $\t \mapsto \etaopt(\t)$.

When, then, is $\etaopt(\t)$ continuously differentiable?  We now state some
sufficient conditions which will allow us to prove that $\t \mapsto \etaopt(\t)$
is continuously differentiable via the implicit function theorem (e.g.,
\citet{krantz:2012:implicit}).  We will state general conditions in terms of a
generic parameter $\theta$, specializing our result to the BNP problem at the
end.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{defn}\deflabel{prior_t}
%
Let $\p(\theta \vert \t)$ be a class of (integrable, possibly non-normalized)
densities relative to a dominating measure, $\lambda$, defined for $\t$ in an
open set $\ball_t$ containing $\t_0$.  Assume that the variational densities
$\q(\theta \vert \eta)$ are defined relative to $\lambda$, and are integrable
(but possibly unnormalized).

Let $\p(\x \vert \theta)$ define a likelihood for the observed data $\x$, let
$\p(\theta, \x \vert \t) = \p(\x \vert \theta) \p(\theta \vert \t)$, and define
%
\begin{align*}
%
\KL{\eta, \t} := \KL{\q(\theta \vert \eta) || \p(\theta \vert \x, \t)}.
%
\end{align*}
%
\end{defn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In \assuref{kl_opt_ok}, we first require some regularity conditions on the KL
divergence and its optimum.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{kl_opt_ok}
%
Let the following conditions on the variational approximation hold.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
%
    \item \itemlabel{kl_diffable} The map $\eta \mapsto \KL{\eta, 0}$ is twice
    continuously differentiable at $\etaopt$.

    \item \itemlabel{kl_opt_interior} The optimal $\etaopt$ is interior
    to $\etadom$.

    \item\itemlabel{kl_hess} The Hessian matrix $\fracat{\partial^2 \KL{\eta,
    0}} {\partial \eta \partial \eta^T} {\etaopt}$ is positive definite.
%
\end{enumerate}
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Our next set of assumptions, \assuref{dist_fun_nice}, states sufficient
conditions for which we can apply the dominated convergence theorem to
variational expectations, allowing us to translate continuity of the variational
and model densitites into continuity of the variational objective.  The details
can be found in \lemref{logq_derivs, logq_continuous} of \appref{cont_lemmas}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{dist_fun_nice}
%
Let $\q(\theta \vert \eta)$ be a (integrable, but possibly unnormalized) density
over the random variable $\theta$ parameterized by $\eta$ defined relative to a
dominating measure $\lambda$.  Assume that the map $\eta \mapsto \log \q(\theta
\vert \eta)$ is twice continuously differentiable.

Let $\psi(\theta, \t)$ be a scalar-valued $\lambda$-measurable function of
$\theta$ and $\t$.  Assume that the map $\t \mapsto \psi(\theta, \t)$ is
continuously differentiable.

Define the following shorthand notation:
%
\begin{align*}
%
\lqgrad{\theta \vert \eta} :={}&
    \fracat{\partial \log \q(\theta \vert \eta)}{\partial \eta}{\eta} \\
%
\lqhess{\theta \vert \eta} :={}&
    \fracat{\partial^2 \log \q(\theta \vert \eta)}
           {\partial \eta \partial \eta^T}{\eta} \\
%
\psigrad{\theta, \t} :={}& \fracat{\partial \psi(\theta, \t)}{\partial \t}{\t}.
%
\end{align*}
%
For a given $\t_0$ and $\eta_0$, assume there exists some neighborhood of
$\t_0$, $\ball_\t$, some neighborhood of $\eta_0$, $\ball_\eta$, and a
$\lambda$-integrable $M_\psi(\theta)$ with $\int M_\psi(\theta) \lambda(d\theta) <
\infty$ such that the following bounds hold for all $\eta, \t \in \ball_\eta
\times \ball_\t$:
%
\begin{enumerate}
%
\item \itemlabel{fundom}
$\q(\theta \vert \eta) \psi(\theta, \t) \le M_\psi(\theta)$.
%
\item \itemlabel{funqgraddom}
$\q(\theta \vert \eta) \norm{\lqgrad{\theta \vert \eta}}_2 \psi(\theta, \t) \le
M_\psi(\theta)$.
%
\item \itemlabel{funqhessdom}
$\q(\theta \vert \eta) \norm{\lqhess{\theta \vert \eta}}_2 \psi(\theta, \t) \le
M_\psi(\theta)$.
%
\item \itemlabel{fungradqgraddom}
$\q(\theta \vert \eta) \norm{\lqgrad{\theta \vert \eta}}_2 \psigrad{\theta, \t}
\le M_\psi(\theta)$.
%
\item \itemlabel{funqgradsqdom}
$\q(\theta \vert \eta) \norm{\lqgrad{\theta \vert \eta}}^2_2 \psi(\theta, \t) \le
M_\psi(\theta)$.
%
\end{enumerate}
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In lieu of \assuref{dist_fun_nice} we might equivalently have said that we can
exchange limits and variational expectations whenever needed,
\assuref{dist_fun_nice} simply being a precise catalogue of what is needed.

Noe that \assuref{dist_fun_nice} and its associated \lemref{logq_derivs,
logq_continuous} of \appref{cont_lemmas}, applied with $\logp(\x \vert \theta)$,
is one way to prove \assuitemref{kl_opt_ok}{kl_diffable}.  Since our primary
focus is on the prior $\logp(\theta \vert \t)$, we prefer to simply state
\assuitemref{kl_opt_ok}{kl_diffable} directly and reserve our detailed attention
for the prior $\logp(\theta \vert \t)$.

Finally, in \assuref{q_stick_regular} we draw the needed connection between the
class of prior perturbations and the variational approximation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{q_stick_regular}
%
Under \defref{prior_t}, assume that the variational densities $\q(\theta \vert
\eta)$ satisfy \assuref{dist_fun_nice} with both $\psi(\theta, \t) \equiv 1$ (no
$\theta$ dependence) and with and $\psi(\theta, \t) = \log \p(\theta \vert \t)$.
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thm}\thmlabel{etat_deriv}
%
Under the conditions of \defref{prior_t}, let \assuref{kl_opt_ok,
q_stick_regular} hold at $\eta_0 = \etaopt$ and $\t_0 = 0$.
Define\footnote{Note that if $\q(\theta \vert \eta)$ is normalized, then
$\expect{\q(\theta \vert \eta)}{\lqgrad{\theta \vert \eta}} = 0$ for all $\eta$
and $\lqgradbar{\theta \vert \etaopt} = \lqgrad{\theta \vert \etaopt}$.  For
convenience we keep the notation general.}
%
\begin{align*}
%
\hessopt :={}& \fracat{\partial^2 \KL{\eta, 0}}
                {\partial \eta \partial \eta^T}
                {\etaopt} \\
\lqgradbar{\theta \vert \etaopt} :={}&
    \lqgrad{\theta \vert \etaopt} -
    \expect{\q(\theta \vert \etaopt)}{\lqgrad{\theta \vert \etaopt}}.
%
\end{align*}
%
Then the map $\t \mapsto \etaopt(\t)$ is continuously differentiable at $\t=0$
with derivative
%
\begin{align}\eqlabel{vb_eta_sens}
%
\fracat{d \etaopt(\t)}{d \t}{0} ={}&
    - \hessopt^{-1}
    \expect{\q(\theta \vert \etaopt)}{
        \lqgradbar{\theta \vert \etaopt}
        \fracat{\partial \log \p(\theta \vert \t)}{\partial \t}{\t=0}
    }.
    % \fracat{\partial^2 \KL{\eta, \t}}
    %        {\partial \eta \partial \t}
    %        {\etaopt, 0}.
%
\end{align}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{proof}
%
For the duration of the proof, define
%
\begin{align*}
%
\rho(\eta, \t) :={}&
    \expect{\q(\theta \vert \eta)}
           {\log \p(\theta \vert \t) - \log \p(\theta \vert 0)}
\mathand\\
\rho_\eta(\eta, \t) :={}&
\fracat{\partial \rho(\eta, \t)}
       {\partial \eta}{\eta}.
%
\end{align*}
%
Expanding $\logp(\theta \vert \t)$ in \eqref{vb_optimization}, we see that
%
\begin{align}
%
% \logp(\theta \vert \t) ={}& \logp(\theta) +
%     \log \p(\theta\vert\t) - \log \p(\theta \vert 0) \Rightarrow \nonumber\\
\KL{\eta, \t} ={}&
    \KL{\eta, 0} + \rho(\eta, \t). \eqlabel{kl_pert}
%
\end{align}
%
% We thus see that the optimization objective $\KL{\eta, \t}$ is the original
% optimization obejctive, $\KL{\eta, 0}$, plus the additive term $\rho(\eta,
% \t)$ depending only on $\eta$ and $\t$.
%
By \lemref{logq_derivs}, $\eta \mapsto \rho(\eta, \t)$ is continuous, and
by \lemref{logq_continuous} $\eta \mapsto \rho(\eta, \t)$ is continuously
differentiable, for all $\eta, \t \in \ball$.  So $\partial \KL{\eta, \t}  /
\partial \eta$ is continuous for all $\eta, \t \in \ball$ and, by the
first-order condition of \eqref{kl_shorthand}, $\etaopt(\t)$ satisfies
%
\begin{align}\eqlabel{vb_first_order_condition}
%
\fracat{\partial \KL{\eta, \t}}{ \partial \eta}{\etaopt(\t), \t} ={}
\fracat{\partial \KL{\eta, 0}}{ \partial \eta}{\etaopt(\t)}
+  \rho_\eta(\etaopt(\t), \t) ={} 0
%
\end{align}
%
for all $\t \in \ball_\t$.

We wish to apply the implicit function theorem to
\eqref{vb_first_order_condition}, for which we must show that $\partial
\KL{\eta, \t} / \partial \eta$ is continuously differentiable in both $\eta$ and
$\t$.  By \assuitemref{kl_opt_ok}{kl_diffable}, $\partial \KL{\eta, 0} /
\partial \eta$ is continuously differentiable, so we need only consider
$\rho_\eta(\theta, \t)$.

By \lemref{logq_continuous} and \assuref{q_stick_regular}, we
have that both $\partial \rho_\eta(\eta, \t) / \partial \eta$ and $\partial
\rho_\eta(\eta, \t) / \partial \t$ are continuous in both $\eta$ and $\t$.
Since both its partial derivatives are continuously differentiable, the joint
map $\eta, \t \mapsto \rho_\eta(\eta, \t)$ is also continuously differentiable
(e.g., \citet[Theorem 3.2]{fleming:2012:functions}).  Consequently, $\partial
\KL{\eta, \t} / \partial \eta$ is continuously differentiable in both $\eta$ and
$\t$.

% This does not appear to be necessary.
% Since $\rho_\eta(\eta, \t)$ is continuously differentiable, $\KLhess{\eta, \t}$
% is continuous, and since $\KLhess{\etaopt, 0}$ is positive definite,
% $\KLhess{\eta, \t}$ is positive definite for all $\eta, \t \in \ball$.

Together with \assuitemref{kl_opt_ok}{kl_hess}, which gives that $\partial^2
\KL{\eta, \t} / \partial \eta \partial\eta^T$ is invertible at $\etaopt$, the
result then follows from the implicit function theorem \citet[Theorem
3.3.1]{krantz:2012:implicit}. For convenience, \tabref{kranz_notation} shows the
correspondence between their notation and ours.
% Note
% that we make the following formal identifications with the notation of
% \citet[Theorem 3.3.1]{krantz:2012:implicit}:

\begin{center}
\begin{tabular}{|c|c|}
%
\hline Krantz \& Parks notation & Our notation \\\hline
$\Phi(x)$                       & $\KL{\eta, \t}$ \\\hline
$Q$                             & $1$ \\\hline
$M$                             & $\etadim$ \\\hline
$U$                             & $\ball$ \\\hline
$W$                             & $\ball_\t$ \\\hline
$x_1,\ldots,x_Q$                & $\t$ \\\hline
$x_{Q+1},\ldots,x_N$            & $\eta$ \\\hline
$f_1(x_a), \ldots,f_M(x_a)$     & $\etaopt(\t)$ \\\hline
%Equation 3.32                   & \assuitemref{kl_opt_ok}{kl_hess} \\\hline
%
\end{tabular}\tablabel{kranz_notation}
\end{center}

The form of the derivative is given by combining \eqref{kl_pert} with
\eqref{q_sens_psi_grad_is_cov} of \lemref{logq_derivs}, since
%
\begin{align*}
%
\fracat{\partial^2 \KL{\eta, \t}}
       {\partial \eta \partial \t}
       {\etaopt, 0} =
\expect{\q(\theta \vert \etaopt)}{
    \lqgradbar{\theta \vert \etaopt}
    \fracat{\partial \log \p(\theta \vert \t)}{\partial \t}{\t=0}
}.
%
\end{align*}
%

%
\end{proof}
%
\end{thm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{cor}\corlabel{gem_approximation_ok}
%
For the variational approximation of \secref{model_vb} and perturbation
given in \exref{alpha_perturbation}, $\alpha \mapsto \etaopt(\alpha)$
is continuously differentiable.

TODO: finish this up.
%
\end{cor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
