Consider the optimization problem \eqref{vb_optimization}, but now let the
priors $\pstick(\nuk)$ which enter the term $\logp(\zeta)$ depend on a
real-valued parameter, $\t \in \tdom \subseteq \mathbb{R}$, writing
$\pstick(\nuk \vert \t)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{ex}\exlabel{alpha_perturbation}
%
When drawing from the classical $\mathrm{GEM}(\alpha)$ distribution, we
model
%
\begin{align*}
%
\pstick(\nuk \vert \alpha) ={}&
    \betadist{\nuk \vert 1, \alpha} \Rightarrow\\
\log \pstick(\nuk \vert \alpha) ={}&
    (\alpha - 1) \log(1 - \nuk) + \const. &
    \constdesc{\nuk}
%
\end{align*}
%
Fix some ``original'' $\alpha_0$.  In this case, we represent deviations from the
choice $\alpha_0$ by identifying $\t$ with $\alpha - \alpha_0$:
%
\begin{align}\eqlabel{gem_alpha_pert}
%
\log \pstick(\nuk \vert \alpha) ={}&
    (\alpha + \alpha_0 - 1) \log(1 - \nuk) + \const.
    %& \constdesc{\nuk}
%
\end{align}
%
\end{ex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In \secref{prior_perturbations}, we will consider a more general class of
perturbations than \exref{alpha_perturbation}.

In any case, the prior on $\zeta$ and posterior in turn depend on $\t$, which we
write $\p(\zeta \vert \x, \t)$. The $\t$ dependence propagates to the optimal
variational parameters as well through the dependence of the KL divergence on
$\t$.  Define the shorthand notation
%
\begin{align}\eqlabel{kl_shorthand}
%
\KL{\eta, \t} := \KL{\q(\zeta \vert \eta) || \p(\x \vert \zeta, \t)}
\mathand
\etaopt(\t) := \argmin_{\zeta \in \etadom} \KL{\eta, \t},
%
\end{align}
%
where we write $\etaopt(\t)$ to emphasize the dependence of the optimum on $\t$.
Without loss of generality, we will continue to use $\etaopt$ with no argument
to refer to $\etaopt(0)$.  That is, we take $\t = 0$ at the ``original''
problem, \eqref{vb_optimization}.

If the map $\t \mapsto \etaopt(\t)$ is continuously differentiable, and we have
already computed the solution $\etaopt$ to the ``original'' problem
\eqref{vb_optimization}, then we can form a Taylor series approximation to
$\etaopt(\t)$.  Specifically, we define
%
\begin{align}\eqlabel{etalin_def}
%
\etalin(\t) := \etaopt + \fracat{d \etaopt(\t)}{d \t}{\t=0} \t .
%
\end{align}
%
Evaluating $\etaopt(\t)$ requires solving a new optimization problem, but, given
$d\etaopt(\t) / d\t | 0$, evaluating $\etalin(\t)$ involves only
multiplication and addition.  When $|\t|$ is small, by continuous
differentiability of $\etaopt(\t)$, we might hope that $\etaopt(\t) \approx
\etalin(\t)$, and so we can use $\etalin(\t)$ to quickly approximate a
time-consuming optimization problem.

Futhermore, or functions of interest $\g(\eta)$ which are themselves
differentiable, we can use the chain rule to compute
%
\begin{align}\eqlabel{vb_g_sens}
%
\fracat{d g(\etaopt(\t))}{d\t} ={}&
    \fracat{\partial g(\eta)}{\partial \eta^T}{\etaopt(\t_0)}
    \fracat{d \etaopt(\t)}{d \t}{\t_0} \\
\glin(\t) :={}& \g(\etaopt(\t_0)) + \fracat{d g(\etaopt(\t))}{d\t}{\t_0} (\t - \t_0).
%
\end{align}
%
For non-differentiable functions of $\eta$, we can still form the approximation
%
\begin{align*}
%
\gapprox(\t) :={}& \g(\etalin(\t)).
%
\end{align*}
%
The advantage of $\glin(\t)$ relative to $\gapprox(\t)$ is that for the former
we can compute influence functions and worst-case perturbations, as we discuss
below in \secref{prior_perturbations}.  Converse, $\gapprox(\t)$ may be expected
to provide a better approximation in some cases since it retains non-linearities
in the map $\eta \mapsto \g(\eta)$, linearizing only the computationally
intensive map $\t \mapsto \etaopt(\t)$.

When, then, is $\etaopt(\t)$ continuously differentiable?  We now state some
sufficient conditions which will allow us to prove that $\etaopt(\t)$ is
continuously differentiable via the implicit function theorem
(e.g., \citet{krantz:2012:implicit}).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{dist_fun_nice}
%
Let $\q(\theta \vert \eta)$ be a (possibly unnormalized) density over the random
variable $\theta$ parameterized by $\eta$ defined relative to a dominating
measure $\lambda$.  Assume that the map $\eta \mapsto \log \q(\theta \vert
\eta)$ is twice continuously differentiable.

Let $\psi(\theta, \t)$ be a scalar-valued $\lambda$-measurable function of
$\theta$ and $\t$.  Assume that the map $\t \mapsto \psi(\theta, \t)$ is
continuously differentiable.

Define the following shorthand notation:
%
\begin{align*}
%
\lqgrad{\theta \vert \eta} :={}&
    \fracat{\partial \log \q(\theta \vert \eta)}{\partial \eta}{\eta} \\
%
\lqhess{\theta \vert \eta} :={}&
    \fracat{\partial^2 \log \q(\theta \vert \eta)}
           {\partial \eta \partial \eta^T}{\eta} \\
%
\psigrad{\theta, \t} :={}& \fracat{\partial \psi(\theta, \t)}{\partial \t}{\t}.
%
\end{align*}
%
For a given $\t_0$ and $\eta_0$, assume there exists some neighborhood of
$\t_0$, $\ball_\t$, some neighborhood of $\eta_0$, $\ball_\eta$, and a
$\lambda$-integrable $M_\psi(\theta)$ with $\int M_\psi(\theta) \lambda(d\theta) <
\infty$ such that the following bounds hold for all $\eta, \t \in \ball_\eta
\times \ball_\t$:
%
\begin{enumerate}
%
\item \itemlabel{fundom}
$\q(\theta \vert \eta) \psi(\theta, \t) \le M_\psi(\theta)$.
%
\item \itemlabel{funqgraddom}
$\q(\theta \vert \eta) \norm{\lqgrad{\theta \vert \eta}}_2 \psi(\theta, \t) \le
M_\psi(\theta)$.
%
\item \itemlabel{funqhessdom}
$\q(\theta \vert \eta) \norm{\lqhess{\theta \vert \eta}}_2 \psi(\theta, \t) \le
M_\psi(\theta)$.
%
\item \itemlabel{fungradqgraddom}
$\q(\theta \vert \eta) \norm{\lqgrad{\theta \vert \eta}}_2 \psigrad{\theta, \t}
\le M_\psi(\theta)$.
%
\item \itemlabel{funqgradsqdom}
$\q(\theta \vert \eta) \norm{\lqgrad{\theta \vert \eta}}^2_2 \psi(\theta, \t) \le
M_\psi(\theta)$.
%
\end{enumerate}
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Assuref{dist_fun_nice} states sufficient conditions for which we can apply the
dominated convergence theorem to varaiational expectations, allowing us to
translate continuity of the variational and model densitites into continuity of
the variational objective.  The details can be found in \lemref{logq_derivs,
logq_continuous} of \appref{cont_lemmas}.  We might equivalently have said that
we can exchange limits and variational expectations whenever needed,
\assuref{dist_fun_nice} simply being a precise catalogue of what is needed.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{kl_opt_ok}
%
Let the following conditions on the variational approximation hold.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
%
    \item \itemlabel{kl_opt_interior} The optimal $\etaopt$ is interior
    to $\etadom$.

    \item \itemlabel{kl_diffable} The map $\eta \mapsto \KL{\eta, 0}$ is twice
    continuously differentiable at $\etaopt$.

    \item\itemlabel{kl_hess} The Hessian matrix $\fracat{\partial^2 \KL{\eta,
    0}} {\partial \eta \partial \eta^T} {\etaopt}$ is positive definite.
%
\end{enumerate}
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{assu}\assulabel{q_stick_regular}
%
Assume that the variational approximations $\q(\nu \vert \etanuk)$ to the
stick-breaking posteriors satisfy \assuref{dist_fun_nice} with $\theta = \nuk$,
$\eta_0 = \etaopt$, and with both $\psi(\theta, \t) \equiv 1$ (no $\theta$
dependence) and with $\theta = \nuk$ and $\psi(\nuk, \t) = \log \pstick(\nuk
\vert \t)$, for all $\k$.
%
\end{assu}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thm}\thmlabel{etat_deriv}
%
Let \assuref{kl_opt_ok, q_stick_regular} hold.  Then the map $\t \mapsto
\etaopt(\t)$ is continuously differentiable with derivative
%
\begin{align}\eqlabel{vb_eta_sens}
%
\fracat{d \etaopt(\t)}{d \t}{0} ={}&
    - \left( \fracat{\partial^2 \KL{\eta, \t}}
                    {\partial \eta \partial \eta^T}
                    {\etaopt, 0} \right)^{-1}
    \fracat{\partial^2 \KL{\eta, \t}}
           {\partial \eta \partial \t}
           {\etaopt, 0}.
%
\end{align}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\begin{proof}
%
For the duration of the proof, define
%
\begin{align*}
%
\rho(\etanuk, \t) :={}&
    \expect{\q(\nu \vert \etanuk)}
           {\log \pstick(\nu \vert \t) - \log \pstick(\nu \vert 0)}
\mathand\\
\rho_\eta(\etanuk, \t) :={}&
\fracat{\partial \rho(\etanuk, \t)}
       {\partial \etanuk}{\etanuk}.
%
\end{align*}
%
Expanding $\logp(\zeta \vert \t)$ in \eqref{vb_optimization}, we see that
%
\begin{align}
%
\logp(\zeta \vert \t) ={}& \logp(\zeta) +
    \sumkm \left( \log \pstick(\nuk\vert\t) -
                  \log \pstick(\nuk \vert 0) \right) \Rightarrow \nonumber\\
\KL{\eta, \t} ={}&
    \KL{\eta, 0} + \sumkm \rho(\etanuk, \t). \eqlabel{kl_pert}
%
\end{align}
%
We thus see that the optimization objective $\KL{\eta, \t}$ is the original
optimization obejctive, $\KL{\eta, 0}$, plus an additive term depending only on
$\etanu$ and $\t$.

By \lemref{logq_derivs}, $\etanuk \mapsto \rho(\etanuk, \t)$ is continuous, and
by \lemref{logq_continuous} $\etanuk \mapsto \rho(\etanuk, \t)$ is continuously
differentiable, for all $\eta, \t \in \ball$.  So $\partial \KL{\eta, \t}  /
\partial \eta$ is continuous for all $\eta, \t \in \ball$ and, by the
first-order condition of \eqref{kl_shorthand}, $\etaopt(\t)$ satisfies
%
\begin{align}\eqlabel{vb_first_order_condition}
%
\fracat{\partial \KL{\eta, \t}}{ \partial \eta}{\etaopt(\t), \t} ={}
\fracat{\partial \KL{\eta, 0}}{ \partial \eta}{\etaopt(\t)}
+  \sumkm \rho_\eta(\etaoptnuk(\t), \t) ={} 0
%
\end{align}
%
for all $\t \in \ball_\t$.
% Recall that the intractable $\logp(\x \vert \t)$
% does not depend on $\eta$, and so vanishes in \eqref{vb_first_order_condition},
% and in all expressions involving partial $\eta$ derivatives of the KL
% divergence.

We wish to apply the implicit function theorem to
\eqref{vb_first_order_condition}, for which we must show that $\partial
\KL{\eta, \t} / \partial \eta$ is continuously differentiable in both $\eta$ and
$\t$.  By \assuitemref{kl_opt_ok}{kl_diffable}, $\partial \KL{\eta, 0} /
\partial \eta$ is continuously differentiable, so we need only consider
$\rho_\eta(\etanuk, \t)$.

By \lemref{logq_continuous} and \assuref{q_stick_regular}, we
have that both $\partial \rho_\eta(\etanuk, \t) / \partial \eta$ and $\partial
\rho_\eta(\etanuk, \t) / \partial \t$ are continuous in both $\eta$ and $\t$.
Since both its partial derivatives are continuously differentiable, the joint
map $\eta, \t \mapsto \rho_\eta(\eta, \t)$ is also continuously differentiable
(e.g., \citet[Theorem 3.2]{fleming:2012:functions}).  Consequently, $\partial
\KL{\eta, \t} / \partial \eta$ is continuously differentiable in both $\eta$ and
$\t$.

% This does not appear to be necessary.
% Since $\rho_\eta(\eta, \t)$ is continuously differentiable, $\KLhess{\eta, \t}$
% is continuous, and since $\KLhess{\etaopt, 0}$ is positive definite,
% $\KLhess{\eta, \t}$ is positive definite for all $\eta, \t \in \ball$.

Together with \assuitemref{kl_opt_ok}{kl_hess}, which gives that $\partial^2
\KL{\eta, \t} / \partial \eta \partial\eta^T$ is invertible at $\etaopt$, the
result then follows from the implicit function theorem \citet[Theorem
3.3.1]{krantz:2012:implicit}. For convenience, \tabref{kranz_notation} shows the
correspondence between their notation and ours.
% Note
% that we make the following formal identifications with the notation of
% \citet[Theorem 3.3.1]{krantz:2012:implicit}:

\begin{center}
\begin{tabular}{|c|c|}
%
\hline Krantz \& Parks notation & Our notation \\\hline
$\Phi(x)$                       & $\KL{\eta, \t}$ \\\hline
$Q$                             & $1$ \\\hline
$M$                             & $\etadim$ \\\hline
$U$                             & $\ball$ \\\hline
$W$                             & $\ball_\t$ \\\hline
$x_1,\ldots,x_Q$                & $\t$ \\\hline
$x_{Q+1},\ldots,x_N$            & $\eta$ \\\hline
$f_1(x_a), \ldots,f_M(x_a)$     & $\etaopt(\t)$ \\\hline
%Equation 3.32                   & \assuitemref{kl_opt_ok}{kl_hess} \\\hline
%
\end{tabular}\tablabel{kranz_notation}
\end{center}
%
\end{proof}
%
\end{thm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{cor}\corlabel{our_approximation}
%
For the variational approximation of \secref{model_vb} and perturbation
given in \exref{alpha_perturbation}, $\alpha \mapsto \etaopt(\alpha)$
is continuously differentiable.
%
\end{cor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
