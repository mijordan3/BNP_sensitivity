Scientists, engineers, and social scientists are often interested in inferring
the number of clusters in a given data set, as well as inferring which data points
belong together. Such inferential questions are often posed within a Bayesian
nonparametric (BNP) framework, building on tools such as the Dirichlet
process~\citep{ferguson:1973:bayesian, sethuraman:1994:constructivedp}.
The Dirichlet process has two useful attributes that have led it to be proposed
as a natural model of clustering phenomena.  First, it is a combinatorial stochastic
process, exhibiting discrete structure that allows multiple data points to be associated
with the same underlying value of a parameter.  Second, its nonparametric nature means
that the number of unique parameter values can grow with the size of the data set, 
accommodating growth in the number of inferred clusters as data accrue.  Such growth
is appropriate in many real-world settings; for example, we might expect to keep
discovering new species as we examine more individual organisms, and we might
expect to discover more topics as we read more articles in a scientific literature.
Finally, the overall Bayesian framework in which the Dirichlet process is embedded
allows clustering to be treated as one aspect of a larger inferential problem.  In
particular, the Dirichlet process can be flexibly incorporated into more complex models
that exhibit other forms of structure, including hierarchical, spatio-temporal, and
topological structure. 

Although the BNP framework offers flexibility, it is important to recognize
that the deployment of a BNP model involves choices of hyperparameters that are
generally made for reasons of mathematical or computational convenience.  Indeed,
the nonparametric nature of BNP models often makes it difficult to express prior
belief subjectively.  For example, the latent frequencies of clusters provided by
the Dirichlet process are obtained by recursively removing beta-distributed fractions
of probability mass from the unit interval. The use of the beta distribution is
motivated by its mathematical tractability under recursion and by the fact that it
yields a form of conditional conjugacy that can be exploited by Gibbs sampling.
It is difficult to imagine motivating such a choice subjectively.  Moreover, having
accepted the beta distribution as a choice of convenience, there remains the problem
of choosing the parameter $\alpha$ associated with this distribution.  This choice
is often made based on previous applications rather than prior belief for the application
at hand \citep[Chapter 23]{teh:2006:hdp, gelman:2013:bda}.

In general we need to recognize that there will exist many possible $\alpha$ values,
and many possible forms of stick-breaking prior, that might correspond to our prior
beliefs but which the Dirichlet process framework makes it difficult to understand
and specify a priori.  Thus, choices of convenience are made, and, unfortunately,
these choices can change the results of a data analysis. For instance, $\alpha$
has a direct, proportional relationship to the number of clusters in the asymptotics
of the Dirichlet process. Thus the number of clusters at any particular data size may
depend strongly on $\alpha$. If our scientific conclusions varied substantially over
seemingly equivalent prior choices, we might worry that these conclusions are
driven not by our data and meaningful prior beliefs but instead by our arbitrary
or default choices. It behooves us, then, to check how sensitive our conclusions
are to these choices.

In practice, Bayesian inference requires not just specification of a model and
collection of data but also the use of some posterior approximation. So when we
assess the sensitivity of our conclusions, we should assess the sensitivity of
the full procedure we use in practice. Variational Bayes (VB) is a particularly
popular posterior approximation method for unsupervised learning problems such
as clustering and topic modeling due its fast computation time, increasingly
automated implementations \citep{ranganath:2013:black, kucukelbir:2016:advi},
and avoidance of the label-switching problem exhibited by MCMC
\citep{jasra:2005:mcmclabelswitch}. Therefore, we imagine in what follows that
we have computed the VB approximation for some clustering quantity of interest,
such as number of clusters or cluster co-occurrence.

With a full methodology for clustering in hand, we now can ask how sensitive our
quantity of interest is to the choices of $\alpha$ and the stick-breaking
distributions. One option is to propose a number of potential $\alpha$ values,
compute the variational approximation at each $\alpha$ value, and report our
quantity of interest for each $\alpha$ value. We might similarly assess
sensitivity to the stick-breaking distribution over a range of distributional
choices. There are at least two major issues with this proposal: (1) while VB is
a relatively fast form of approximation Bayesian inference in general, it may
still be prohibitively expensive to have to re-run it many times and (2) it is
unclear how best to choose a collection of $\alpha$ and (especially) the
stick-breaking distribution values -- and how many to choose.

In this work, we circumvent these challenges with a local approximation. VB
posits posterior approximation as an optimization problem. So we show how to
approximate the nonlinear dependence of the VB optimum on prior choices using a
first-order Taylor series expansion. We build on the local robustness tools
developed by \cite{giordano:2018:covariances} for VB and
\cite{gustafson:1996:local} for MCMC. To enable their application to VB for BNP
clustering, we solve a number of open problems; indeed the techniques we
introduce in the current work may be seen to advance sensitivity for VB more
broadly. (1) In particular, we establish that the optimal VB parameters are a
continuously differentiable function of $\alpha$ and the stick-breaking form.
(2) We show that the sensitivity of the VB approximation to functional prior
perturbations takes the form of an integral against a computationally tractable
\textit{influence function} -- and illustrate how the influence function can
provide an interpretable summary of the effect of arbitrary changes to the prior
density. (3) To justify using linear approximations over a ball describing
different stick-breaking densities, we show that our approximation is
\textit{uniformly} good by establishing Fr\'echet differentiability. (4) We show how
to efficiently compute our approximation even in high-dimensional problems,
e.g.\ as arise in BNP models. (5) We establish the accuracy, practicality, and
speed of our approximation for a variety of models that use stick-breaking, and
for various quantities of interest in both clustering and topic modeling.
