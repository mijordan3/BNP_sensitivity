Two central goals of many clustering problems are inferring how many distinct
clusters are present in a particular dataset and which observations cluster
together. A Bayesian nonparametric (BNP) approach to clustering assumes an
infinite number of \textit{components}, of which a finite number are present in
the data as \textit{clusters}. Being a Bayesian approach, BNP places a
generative process on cluster assignment, and inference about any quantity of
interest, such as number of distinct clusters present in a data set, is entirely
defined by the posterior distribution. Like all Bayesian approaches, BNP
requires the specification of a prior, and this prior may favor a greater or
fewer number of distinct clusters. In practice, it is important to establish
that the prior is not too informative, particularly when---as is often the case
in BNP---the particular form of the prior is chosen for mathematical convenience
rather than because of a considered subjective belief.

Consider, as a simple motivating example, a field biologist fitting a Gaussian
mixture model (GMM) fit to the Fisher iris dataset \citep{anderson:1936:iris,
fisher:1936:iris} using a Dirichelt process prior with concetration parameter
$\alpha$.  One might imagine the biologist asking: ``Suppose I went out and
gathered a new dataset the same size as the one I have.  How many distinct
species of iris would I expect to find?''  This posterior predictive expectation
of the number of distinct species may depend strongly on the choice of the
concetration parameter $\alpha$ as $\alpha$ varies over some reasonable range,
and, if it does, the biologist would presumably like to be warned that her
posterior quantity of interest is {\em non-robust} to the choice of $\alpha$.

The posterior in a BNP model cannot be calcluated analytically, and thus
approximate methods are required in practice. In the present work, we consider
inference using variational Bayes (VB), which posits a constrained family of
distributions, and uses optimization to find the member of the family that is
closest to the true posterior in Kullback-Leibler ($\mathrm{KL}$) divergence
\citep{blei:2017:vi_review, blei:2006:vi_for_dp}. VB is a popular method on
large-scale data sets because solving the optimization problem can be much
faster than running Markov chain Monte Carlo (MCMC). VB is particularly apt for
data analysis problems that are exploratory in nature, and where quick,
approximate solutions suffice.

Concretely, the output of a VB approximation is a vector of optimal
approximating parameters, which we can denote as $\etaopt$.  For instance,
$\etaopt$ might be a vector of approximating exponential family natural
parameters for all the quantities in the posterior.  In our example, evaluating
$\etaopt$ for a particular prior parameter $\alpha$ means solving an
optimization problem whose objective function depends on $\alpha$, and we notate
the resulting dependence of $\etaopt$ on $\alpha$ as $\etaopt(\alpha)$.
%
Posterior quantites of interest, such as posterior expectations, can be
approximated using expectations of the variational distributions, which in turn
are functions of the VB parameters $\etaopt(\alpha)$. For example, in our
motivating example, can write $\alpha \mapsto \g(\etaopt(\alpha))$ as the map
from a choice of prior concentration parameter to our approximate posterior
quantity of interest.

A conceptually straightforward way to assess the robustness of
$\g(\etaopt(\alpha))$ to $\alpha$ would be to refit the VB posterior for several
different plausible prior choices.  For example, one might find
$\etaopt(\alpha_g)$ for each $\alpha_g \in \{\alpha_1, \ldots, \alpha_G \}$ in a
grid of $G$ plausible values.  If $\g(\etaopt(\alpha_g))$ varies meaningfully,
we would say that the quantity $\g(\cdot)$ is non-robust to the choice of
$\alpha$.  However, repeatedly finding variational optima for each prior choice
may be unnecessarily expensive, particularly for the settings we consider where
approximate optima might suffice.

In this work, we circumvent the need for repeated optimization by approximating
the nonlinear dependence of the VB optimum on prior parameters using a
first-order Taylor series expansion.  Starting with an initial VB optimum, we
use the Taylor expansion to quickly extrapolate the values of posterior
quantities that would be obtained after a model perturbation, without having to
refit the VB posterior.  In our example, we would choose some ``base value''
$\alpha_0$ of the concentration parameter, solve the optimization problem to
compute $\etaopt(\alpha_0)$, and use $\etaopt(\alpha_0)$ to approximate
%
\begin{align*}
%
% \etaopt(\alpha) \approx
\etalin(\alpha) :=
    \etaopt(\alpha_0) +
    \fracat{d\etaopt(\alpha)}{d\alpha}{\alpha_0} (\alpha - \alpha_0)
\mathand
g(\etaopt(\alpha)) \approx g(\etalin(\alpha)).
%
\end{align*}

If the map $\alpha \mapsto \etaopt(\alpha)$ is continuously differentiable, then
we expect $g(\etaopt(\alpha)) \approx g(\etalin(\alpha))$ when $\abs{\alpha -
\alpha_0}$ is small.  And if the derivative $d\etaopt(\alpha) / d\alpha$ can be
computed much more efficiently than the cost of optimizing directly,
$\etalin(\alpha)$ can be much faster to compute than $\etaopt(\alpha)$.  Even
when the approximation $\etalin(\alpha)$ is not a completely adequate substitue
for exact re-optimization, the derivative can be a useful guide for what sorts
of prior perturbations might be problematic, informing futher exploration based
on re-optimizing.

The approximation thus motivates three key questions:
%
\begin{enumerate}
%
\item \itemlabel{intro_diff}
    When are the optimal VB parameters a continuously differentiable
    function of the prior?
%
\item \itemlabel{intro_comp}
    How can we easily and efficiently compute the derivative?
%
\item \itemlabel{intro_extrap}
    How well does the linear approximation extrapolate to reasonable
    alternative priors in real-world problems?
%
\end{enumerate}
%
For the remainder of the paper, we address these three questions, after
introducing our BNP model and VB approximation in \secref{model}.

In \secref{local_sensitivity}, we state sufficient conditions for
differentiability of VB approximations in general, both for parametric
perturbations such as the concentration parameter $\alpha$, as well as for
nonparametric perturbations to the prior density.  The differentiability of our
motivating BNP problems follow as a special case.  Amongst a class of
nonparametric perturbations considered by \citet{gustafson:1996:local}, we prove
that VB optima are Fr{\'e}chet differentiable only for multiplicative
perturbations to the prior density.  Furthermore, we show that the sensitivity
of the VB approximation to nonparametric prior perturbations takes the form of
an integral against a computationally tractable \textit{influence function},
which can provide an interpretable summary of the effect of arbitrary changes to
the prior density.

In \secref{computing_sensitivity}, we address practical computability of the
derivative, and show that the approximation can be easily and efficiently
computed even in high-dimensional problems like BNP models, using modern
automatic differentiation tools \citep{baydin:2018:automatic, jax2018github} and
iterative linear algebra techniques such as the conjugate gradient algorithm
\citep{nocedal:2006:numerical}.  In our experiments, we find that the  needed
derivatives can be computed roughly an order of magnitude faster than
re-optimizing.

Finally, in \secref{results}, we demonstrate the usefulness of the approximation
in practice on a series of increasingly complex real-world datasets.  We
investigate the accuracy of our local approximation both for parametric and
nonparametric perturbations by comparing against the much more expensive process
of refitting the variational posterior.  We demonstrate how different posterior
quantities can be sensitive or non-sensitive, depending on both the application
and the quantity of interest.  In most cases, the local approximation provides
qualitatively accurate results many times faster re-optimizing.  We also discuss
some limitations of local sensitivity and present scenarios where it fails to be
a good approximation to refitting.

We close the introduction by observing that  the present work is essentially a
VB extension of the local Bayesian robustness literature, which was
traditionally based on Markov Chain Monte Carlo (MCMC)
\citet{gustafson:1996:local, basu:1996:local}.  In a sense, VB is more naturally
amenable to sensitivity analysis than MCMC, since the derivative of VB
approximations is typically available in closed form, whereas the derivative of
Bayesian posteriors must be approximated using potentially noisy posterior
covariances and/ or posterior conditional densities that are not readily
available from MCMC draws (e.g., \citet{gustafson:1996:marginal}).  In addition
to providing rigorous theory and computational tools for the VB context, we go
beyond previous work on local Bayesian sensitivity by paying special attention
to our ability to accurately and usefully \textit{extrapolate} VB posterior
inferences to different priors, rather than simply considering large derivatives
to be indicative of non-robustness \textit{per se}.
