Scientists, engineers, and social scientists are often interested in inferring
the number of clusters in a given data set, as well as which observations
cluster together. A common methodology builds on the Dirichlet process
\citep{ferguson:1973:bayesian, sethuraman:1994:constructivedp} from Bayesian
nonparametrics (BNP). BNP methods offer a number of favorable properties. They
allow the number of clusters to grow with the size of the data set; for example,
we might expect to keep discovering new species as we examine more individual
organisms, and we might expect to discover more topics as we read more articles
in a scientific journal. Moreover, BNP methods can be flexibly incorporated into
models of varying complexity. And the Dirichlet process in particular offers a
convenient and well-studied prior on the number and assignment of clusters --
facilitating Bayesian posterior inference and a resulting coherent
quantification of uncertainty.

Nonetheless, Bayesian modeling often involves choices of convenience rather than
pure subjective prior elicitation, and Dirichlet process models are no
exception. For instance, the latent frequencies of clusters -- i.e., the
component proportions -- in a Dirichlet process are generated by recursively
removing beta-distributed fractions of probability mass from the unit interval.
The beta distribution is historically convenient for approximate inference
methods (such as Gibbs sampling) that rely on conditional conjugacy but need not
represent a strong prior belief. Similarly, the Dirichlet process concentration
parameter $\alpha$ may often be chosen based on previous applications rather
than prior belief for the application at hand.
\todo{Cite something (Ryan doesn't have ideas.)}

In general, then, there often exist many possible $\alpha$ values, and many
possible forms of stick-breaking, that might correspond to our prior beliefs.
And these choices can change the results of a data analysis. For instance,
$\alpha$ asymptotically serves as a proportionality constant for the number of
clusters. So the number of clusters at any particular data size may depend
strongly on $\alpha$. If our scientific conclusions varied substantially over
seemingly equivalent prior choices, we might worry that these conclusions are
driven not by our data and meaningful prior beliefs but instead by
somewhat-arbitrary aspects of implementation. It behooves us, then, to check how
sensitive our conclusions are to these choices.

In practice, Bayesian inference requires not just specification of a model and
collection of data but also the use of some posterior approximation. So when we
assess the sensitivity of our conclusions, we should assess the sensitivity of
the full procedure we use in practice. Variational Bayes (VB) is a particularly
popular posterior approximation method for unsupervised learning problems such
as clustering and topic modeling due its fast computation time, increasingly
automated implementations \citep{ranganath:2013:black, kucukelbir:2016:advi},
and avoidance of the label-switching problem exhibited by MCMC
\citep{jasra:2005:mcmclabelswitch}. Therefore, we imagine in what follows that
we have computed the VB approximation for some clustering quantity of interest,
such as number of clusters or cluster co-occurrence.

With a full methodology for clustering in hand, we now can ask how sensitive our
quantity of interest is to the choices of $\alpha$ and the stick-breaking
distributions. One option is to propose a number of potential $\alpha$ values,
compute the variational approximation at each $\alpha$ value, and report our
quantity of interest for each $\alpha$ value. We might similarly assess
sensitivity to the stick-breaking distribution over a range of distributional
choices. There are at least two major issues with this proposal: (1) while VB is
a relatively fast form of approximation Bayesian inference in general, it may
still be prohibitively expensive to have to re-run it many times and (2) it is
unclear how best to choose a collection of $\alpha$ and (especially) the
stick-breaking distribution values -- and how many to choose.

In this work, we circumvent these challenges with a local approximation. VB
posits posterior approximation as an optimization problem. So we show how to
approximate the nonlinear dependence of the VB optimum on prior choices using a
first-order Taylor series expansion. We build on the local robustness tools
developed by \cite{giordano:2018:covariances} for VB and
\cite{gustafson:1996:local} for MCMC. To enable their application to VB for BNP
clustering, we solve a number of open problems; indeed the techniques we
introduce in the current work may be seen to advance sensitivity for VB more
broadly. (1) In particular, we establish that the optimal VB parameters are a
continuously differentiable function of $\alpha$ and the stick-breaking form.
(2) We show that the sensitivity of the VB approximation to functional prior
perturbations takes the form of an integral against a computationally tractable
\textit{influence function} -- and illustrate how the influence function can
provide an interpretable summary of the effect of arbitrary changes to the prior
density. (3) To justify using linear approximations over a ball describing
different stick-breaking densities, we show that our approximation is
\textit{uniformly} good by establishing Fr\'echet differentiability. (4) We how
to efficiently compute our approximation even in high-dimensional problems,
e.g.\ as arise in BNP models. (5) We establish the accuracy, practicality, and
speed of our approximation for a variety of models that use stick-breaking, and
for various quantities of interest in both clustering and topic modeling.
